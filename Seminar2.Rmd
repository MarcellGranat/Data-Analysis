# Markdown & Tidyverse {#seminar2}

## Markdown

Last week we wrote or codes on the `Source` pane, and if you save the codes and revisit the file with your file explorer, you can see that the extension of the file is `.R`. You can open the file with any other text editor (like Notepad) and see the codes. In a `.R` file you can write your codes and comments, and if you hit `ctrl + shift + enter` then all lines will be evaluated. Most of the times the goal to use `.R` files is this, we want to reuse the codes frequently (like downloading data from a website).

Another possible extension for your files is the `.Rmd`, which stands for *R MarkDown*. In this file format you can combine text, R codes and their output into one single document. from now, We will use `RMarkdown` during the class. Please visit the following website to find useful examples: <https://rmarkdown.rstudio.com/articles_intro.html>

## Introduction to the tidyverse

We will work with the tidyverse today. You can simply install it from the CRAN (go to `Packages` pane and click the install button). But tidyverse is not a simple package. "The tidyverse is a set of packages that work in harmony because they share common data representations [...]"

`Tidyverse` contains the most important packages that you're likely to use in everyday data analyses:

-   [ggplot2](https://ggplot2.tidyverse.org/), for data visualisation.

-   [dplyr](https://dplyr.tidyverse.org/), for data manipulation.

-   [tidyr](https://tidyr.tidyverse.org/), for data tidying.

-   [readr](https://readr.tidyverse.org/), for data import.

-   [purrr](https://purrr.tidyverse.org/), for functional programming.

-   [tibble](https://tibble.tidyverse.org/), for tibbles, a modern re-imagining of data frames.

-   [stringr](https://github.com/tidyverse/stringr), for strings.

-   [forcats](https://github.com/tidyverse/forcats), for factors.

After you installed the packages, you can load in the core packages with \`library\` command. You will receive a warning message, but do not worry, this is fine.

```{r message=T, warning=T}
library(tidyverse)
```

## The `%>%` operator

This operator is written `ctrl + shift + m`, it is denoted as `%>%`, but we pronounce as **pipe**. To understand its relevance, you should think about it like *... then*. This opreator forward the value of the previous expression into the next function as the first unspecified input. Lets see an example:

We first generate a numerical vector as trajectories of standard normal distribution.

```{r fig.cap="Histogram of standard normal distribution"}
norm_sample <- rnorm(n = 1000, mean = 0, sd = 1) # standard normal
```

**AND THEN** we visualize its distribution with a histogram.

```{r fig.cap="Histogram of standard normal distribution"}
hist(norm_sample)
```

Now we had to assign the `norm_sample` object to use only for a single graph. If you are working on a project it will be confusing to have tons of one time used objects in your `environment` (Like `DataFrameAfterCleaningStep1`, `DataFrameAfterCleaningStep2`, `DataFrameAfterCleaningStep3`, etc.).

With the pipe operator we can embed several steps into one single workflow. This way we do not have to assign the `norm_sample` object. We simple generate the random values AND THEN draw their distribution.

```{r fig.cap="Histogram of standard normal distribution using the pipe"}
rnorm(n = 1000, mean = 0, sd = 1) %>% 
  hist()
```

You may see that the title of plot has changed (probably the graph also changed a bit, since chances are low that we generate exactly the 1000 random values). This is because pipe and many other tidyverse function works with a *lambda like* function framework. This means that you can refer to the input value (only if you have only one single input) with `.`.

Example:

```{r}
(2 + 2) %>% 
  {. * .}
```

The result is 16, since 2 + 2 = 4, and 4 \* 4 equals 16.

The pipe may seem unrelevant first, but this is one of the most powerful tool in R if you have complex data manipulating steps. We will cover the core functions of `dplyr` in this chapter, which appear in the following video (37:30 - 38:30), but when you are familier with them, you will see the motivation behind the pipe.

<iframe width="560" height="315" src="https://www.youtube.com/embed/8SGif63VW6E?start=2249" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>

</iframe>

## Tibble, count, filter, select, arrange

### Tibble

Let's import a dataset from the [OECD webpage](https://data.oecd.org/pop/fertility-rates.htm#indicator-chart). Download the data in csv format and paste it into your working directory.

```{r }
fertility_df <- read_csv("DP_LIVE_22092021161631568.csv")
```

`read_csv` is importad from the `readr` package, thus shares its output is adequat to the tidyverse principles. `fertility_df` is a data.frame, but it is a `tibble`, which means that it will be printed nicely on the console: only the first 10 rows appears, and only the amount of columns that can be printed without a linebreak (similar to pandas dataframe in python).

```{r}
fertility_df
```

### Count

With the `count` function you can simple *count* the number of appearancesof the levels of a given column. Example:

```{r}
count(fertility_df, LOCATION)
```

Now we can see that we have 60 observation from ARG. If you are interested in for which country we have the most datapoints, you can use the `sort = TRUE` option.

```{r}
count(fertility_df, LOCATION, sort = TRUE)
```

You can also use the pipe here[\^It would not be a good solution to assign a new dataframe to each count table]

```{r}
fertility_df %>% # %>% = the 1st argument of count function is the fertility_df data.frame
  count(LOCATION)
```

You may specifiy multiple columns, this way the frequency of all value combinaton appears.

```{r}
fertility_df %>% 
  count(LOCATION, TIME, sort = T)
```

Now we see that we have only one observation for each country at a time, so this data frame was originally tidy (this is usually not the case). Let's see for example the Q GDP data from the [OECD webpage](https://data.oecd.org/gdp/quarterly-gdp.htm).

```{r}
gdp_df <- read_csv("DP_LIVE_22092021163414835.csv")
```

Using the `count` function, we may find that `MEASURE`, `SUBJECT` & `FREQUENCY` columns have multiple levels.

```{r}
gdp_df %>% 
  count(MEASURE, SUBJECT, FREQUENCY)
```

Let's say we are interested only in the observations where the `SUBJECT` is equal to TOT (total), `MEASURE` is equal to PC_CHGPY (percentage change to previous value) and the `FREQUENCY` is not equal to A (only quarterly observations). *You can select rows by using the* `filter` function. Its 1st argument is the dataframe you want to modify, and the other arguments are conditional statements. If all the statements are TRUE, then the row will be selected.

```{r}
filter(gdp_df, SUBJECT == "TOT", MEASURE == "PC_CHGPY", FREQUENCY != "A")
```

Just like the `count`, we use this function with `%>%` operator, and use `&` instead of `,`, but if you wish to use *"OR"*, then you can use `|` between two statement.

```{r}
gdp_df %>% 
  filter(SUBJECT == "TOT" & MEASURE == "PC_CHGPY" & FREQUENCY != "A")
```

### Mutate

In the `gdp_df` dataframe you can find the `TIME` column and that its class character. Lets say we want to change this to date. Functions related to date are in the `lubridate` package. Since the values of the `TIME` column consist of a *y*ear and a *q*uarter, we will use the `yq` function to change it into date. But we should not forget that this will work only with the datapoints where the `FREQUENCY` is not annual. So let's keep the previous filter. If we want to modify a given column of a dataframe we should use the `mutate` function. With the pipe operator we now combine the `filter` and the `mutate` command.

```{r}
gdp_df %>% 
  filter(SUBJECT == "TOT" & MEASURE == "PC_CHGPY" & FREQUENCY != "A") %>% 
  mutate(TIME = lubridate::yq(TIME))
```

Now that `TIME` is already a date column, we can add an additional condition: we want to analyze only the latest valuse (where the value of `TIME` is maximum).

```{r}
gdp_df %>% 
  filter(SUBJECT == "TOT" & MEASURE == "PC_CHGPY" & FREQUENCY != "A") %>% 
  mutate(TIME = lubridate::yq(TIME)) %>% 
  filter(TIME == max(TIME)) 
```

Let's where we find the highest values. We have to change the order of the rows with the `arrange` function. If you want to set decreasing order, then you should put the columns name into the `desc` command.

```{r}
gdp_df %>% 
  filter(SUBJECT == "TOT" & MEASURE == "PC_CHGPY" & FREQUENCY != "A") %>% 
  mutate(TIME = lubridate::yq(TIME)) %>% 
  filter(TIME == max(TIME)) %>%
  arrange(desc(Value)) 
```

And we want to remove the unused columns. You can select columns with the `select` function.

```{r}
gdp_df %>% 
  filter(SUBJECT == "TOT" & MEASURE == "PC_CHGPY" & FREQUENCY != "A") %>% 
  mutate(TIME = lubridate::yq(TIME)) %>% 
  filter(TIME == max(TIME)) %>% 
  arrange(desc(Value)) %>% 
  select(geo = LOCATION, gdp_change = Value) # select the LOCATION & gdp_change columns
```

Alternative notation with select:

```{r}
gdp_df %>% 
  select(1) # select the 1st column

gdp_df %>% 
  select(-1) # omit the 1st column

gdp_df %>% 
  select(1:2) # select all the columns between the 1st and the 2nd

gdp_df %>% 
  select(LOCATION:TIME) # select all the columns between the LOCATION and the TIME column

gdp_df %>% 
  select(TIME, LOCATION, everything()) 
  # select all the columns, but TIME & LOCATION to the first place
```

## `Group_by`, `Summary`

Let's see another source for data. You can easily access Eurostat tables with the `eurostat` package.

```{r}
eurostat::search_eurostat("birth")
```

Let's choose the "Live births by mother's age and NUTS 2 region" dataset.

```{r}
livebirth_eu_df <- eurostat::get_eurostat("demo_r_fagec")

livebirth_eu_df
```

First of all, we are interested in NUTS 2 reginal data. But in this dataset national aggregated values are also published (where the geo codes length is only 2 characters). Let's remove these.

```{r}
livebirth_eu_df %>% 
  filter(str_length(geo) != 2)
```

We also should remove the aggregated values and keep only the latest one.

```{r}
livebirth_eu_df %>% 
  filter(str_length(geo) != 2) %>% 
  filter(age != "TOTAL" & time == "2019-01-01") %>% 
  filter(!(age %in% c("UNK", "Y_GE45", "Y_GE48", "Y_GE50", "Y_LT16")))
```

Now our dataset is clean: we have one observation to each geo and age category. Let's suppose we are interested in the total number of birth by the mothers age in EU (I know we would found a table for this). For this we want to sum the values in the `values` column by age category.

```{r eval=F}
livebirth_eu_df %>% 
  filter(str_length(geo) != 2) %>% 
  filter(age != "TOTAL" & time == "2019-01-01") %>% 
  filter(!(age %in% c("UNK", "Y_GE45", "Y_GE48", "Y_GE50", "Y_LT16"))) %>% 
  group_by(age) %>%
  summarise(values = sum(values))
```

```{r echo=F}
livebirth_eu_df %>% 
  filter(str_length(geo) != 2) %>% 
  filter(age != "TOTAL" & time == "2019-01-01") %>% 
  filter(!(age %in% c("UNK", "Y_GE45", "Y_GE48", "Y_GE50", "Y_LT16"))) %>% 
  group_by(age) %>%
  summarise(values = sum(values)) %>% 
  knitr::kable()
```

## Pivot longer/wider

Let's assume we are interested in the growth rate of fertility in each country. First, we should write a function to calculate growth rates (chain index).

```{r}
chain_index <- function(x) {
  scales::percent(x/lag(x)-1, accuracy = .01)
  # lag: previous observation
}
```

Example:

```{r}
x <- c(100, 107, 105, 110)

chain_index(x)
```

```{r eval = F}
fertility_df %>% 
  select(LOCATION, TIME, Value) %>% 
  mutate(GrowthRate = chain_index(Value))
```

(I hided the rest of the table)

```{r echo = F}
fertility_df %>% 
  select(LOCATION, TIME, Value) %>% 
  mutate(GrowthRate = chain_index(Value)) %>% 
  head(70) %>% 
  knitr::kable()
```

But the problem comes at the `GrowthRate` at AUT in 1960, since now (check in the table):

$$\text{Growth}_{\text{AUT}, 1960} = \frac{\text{AUS}_{2019}}{\text{AUT}_{1960}}$$

We can easily solve this by transforming the structure of the table. We need to make the table **wider** in this case, with the `pivot_wider`. this function will create a new column to each level of a seleceted variable.

```{r}
fertility_df %>% 
  select(geo = LOCATION, time = TIME, fertility = Value) %>% 
  pivot_wider(names_from = "geo", values_from = "fertility")
```

If we use the `chain_index` function now on all the columns, then we can avoid the previous bug. You can use a function on all columns (except on the first) with the `mutate_at` function.

```{r}
fertility_df %>% 
  select(geo = LOCATION, time = TIME, fertility = Value) %>% 
  pivot_wider(names_from = "geo", values_from = "fertility") %>% 
  mutate_at(-1, chain_index)
```

And now let's transform the table to its original structure. You can do this with the `pivot_longer` column.

```{r}
fertility_df %>% 
  select(geo = LOCATION, time = TIME, fertility = Value) %>% 
  pivot_wider(names_from = "geo", values_from = "fertility") %>% 
  mutate_at(-1, chain_index) %>% 
  pivot_longer(-1, names_to = "geo", values_to = "fertility")
```

## `Group_modify`

Alternativly, we could solve this problem if we split the data frame into 63 individual data frames (one for each country). If you use the following syntax, you will get the correct results:

```{r eval = F}
fertility_df %>% 
  select(geo = LOCATION, time = TIME, fertility = Value) %>% 
  arrange(time) %>% 
  group_by(geo) %>% 
  group_modify(~ mutate(.x, fertility_growth = chain_index(fertility)), .keep = F)
```

```{r echo = F}
fertility_df %>% 
  select(geo = LOCATION, time = TIME, fertility = Value) %>% 
  arrange(time) %>% 
  group_by(geo) %>% 
  group_modify(~ mutate(.x, fertility_growth = chain_index(fertility)), .keep = F) %>% 
  head(70) %>% 
  knitr::kable()
```

## Exercise

You have to get to know your classmates to solve this exercise.

1.  Create a new .Rmd file

2.  Import the da_q.csv data into R with relative referencing (see Chapter \@ref(data-import))

3.  Write down the information you know about at least 3 of your teammates (Names are neccesary) as text in the `.Rmd`.

4.  Write R codes to find the teammates (write also comments in the code^["A comment always writes down the why, not the what"]) using only base R function (tools you have learned in the 1st seminar).

5.  Write R codes to find the teammates using dplyr function (tools you have learned in the 2nd seminar)

**You found your teammate if the output of an R code is correct ID number of the person.**

Example:

```{r echo=F}
df <- read_delim(str_c(WD, "/data/da_q.csv"), delim = ";", escape_double = FALSE, trim_ws = TRUE)
```

```{r}
df
```

*I am from Hungary, and the national food in Hungary is gulash.*

```{r}
df %>% 
  filter(str_detect(`What is the traditional food in your country? (you can mention more, if you wish)`, "gulash")) %>% 
  pull(ID)
```

*So my ID number is 1.*

Of course, you can not choose me. :)