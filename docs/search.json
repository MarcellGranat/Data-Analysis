[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"hope message finds well.online bookdown file, plan update regularly class material. suggest write code simultaneously us seminar, bugs can always occur blue… missed something just want revisit topic additional comments (probably exam day) page help.end course know:data types, data quality, data preprocessing?data types, data quality, data preprocessing?components tidyverse advantage?components tidyverse advantage?density, distribution function, quantile functions?density, distribution function, quantile functions?data clustering techniques?data clustering techniques?main techniques association analysis?main techniques association analysis?work R, one loved statistical programming language. afraid programming experience, beginner course. However, end program, hope find useful concept practical tips offer, able solve real life data analysis issues.","code":""},{"path":"syllabus.html","id":"syllabus","chapter":"Syllabus","heading":"Syllabus","text":"","code":""},{"path":"syllabus.html","id":"topics","chapter":"Syllabus","heading":"0.1 Topics","text":"Basic R knowledge (Week 1)\nData categorize, sampling, importing-exporting\nTypes, tables, selection, objects, functions\nBasic R knowledge (Week 1)Data categorize, sampling, importing-exportingData categorize, sampling, importing-exportingTypes, tables, selection, objects, functionsTypes, tables, selection, objects, functionsData manipulation Tidyverse (Week 2)\nFilter, group_by, arrange, summarize commands\n%>%\nJoin (mutating, filtering)\ntidy data (longer, wider)\nData manipulation Tidyverse (Week 2)Filter, group_by, arrange, summarize commandsFilter, group_by, arrange, summarize commands%>%%>%Join (mutating, filtering)Join (mutating, filtering)tidy data (longer, wider)tidy data (longer, wider)Visualization ggplot2 (Week 3)\nLayers, facets, geoms\nDescriptive statistics R\nSummary statistics, variability, correlation, covariance\nExtreme values, problem missing values\nVisualization ggplot2 (Week 3)Layers, facets, geomsLayers, facets, geomsDescriptive statistics RDescriptive statistics RSummary statistics, variability, correlation, covarianceSummary statistics, variability, correlation, covarianceExtreme values, problem missing valuesExtreme values, problem missing valuesStatistical estimation (Week 4)\nDistributions\nSample techniques, confidence intervals, standard error\nStatistical estimation (Week 4)DistributionsSample techniques, confidence intervals, standard errorHypothesis testing (Week 5)\nInductive statistics R\nNull alternative hypothesis, t-test, p-value, fals\npositive/negative, Type II error\nHypothesis testing (Week 5)Inductive statistics RInductive statistics RNull alternative hypothesis, t-test, p-value, fals\npositive/negative, Type II errorNull alternative hypothesis, t-test, p-value, fals\npositive/negative, Type II errorHypothesis testing II (Week 6)\nRelation testing R\nHypothesis testing II (Week 6)Relation testing RProject presentations (Week 7)Project presentations (Week 7)","code":""},{"path":"syllabus.html","id":"requirements","chapter":"Syllabus","heading":"0.2 Requirements","text":"Test (30%): 90 min task solution R + explanation (exam week)Test (30%): 90 min task solution R + explanation (exam week)Project (25%): groups (3-4 students), one detailed report\n(essay) one - presentationProject (25%): groups (3-4 students), one detailed report\n(essay) one - presentationHomeworks essays (45%)Homeworks essays (45%)Extra tasks (+5%)Extra tasks (+5%)","code":""},{"path":"syllabus.html","id":"project","chapter":"Syllabus","heading":"0.2.1 Project","text":"end course make statistical report research project small groups. find proper dataset (kaggle, eurostat, UCI datasets etc.) conduct survey optional topic.week 7 hold presentation findings results. end week upload detailed essay project work.","code":""},{"path":"syllabus.html","id":"homework","chapter":"Syllabus","heading":"0.2.2 Homework","text":"Study period get 3-5 homeworks. number homeworks depends ont material progress. R code writing R code writing analysis (short essay methods results).Grades","code":""},{"path":"syllabus.html","id":"recommended-compulsory-reading","chapter":"Syllabus","heading":"0.3 Recommended (compulsory) reading","text":"Grolemund G & Wickham H:\nR Data ScienceGrolemund G & Wickham H:\nR Data ScienceGábor Békés & Gábor Kézdi: Data Analysis:\nPatterns, Prediction CausalityGábor Békés & Gábor Kézdi: Data Analysis:\nPatterns, Prediction Causality","code":""},{"path":"seminar1.html","id":"seminar1","chapter":"1 Introduction to R","heading":"1 Introduction to R","text":"","code":""},{"path":"seminar1.html","id":"why-r","chapter":"1 Introduction to R","heading":"1.1 Why R?","text":"chapter discuss basics R programming.\nR free software, used millions field statistics, data science, economics many others.R programming language important tool data related tasks, much .\nJust like programming languages, R many additional packages, can extend basic functionality.\nR great (probably best) graphical tools create charts, shiny, can easily build minimalist web applications.\nlearn data manipulation, analysis create awesome reports, like dashboards.","code":""},{"path":"seminar1.html","id":"layout","chapter":"1 Introduction to R","heading":"1.2 Setup","text":"can download R RStudio official site RStudio.\nPlease install appropriate version based OS, forget also install R well.Run R’s installer file downloading process finished.\nNext, also need RStudio.installation process R RStudio finished, can open RStudio start learn software.","code":""},{"path":"seminar1.html","id":"our-first-meet-with-r","chapter":"1 Introduction to R","heading":"1.3 Our first meet with R","text":"RStudio dedicated IDEE R, means, make life much simplier.\nstead writing line code ourself, RStudio many built-functions help us.\nsee panes open RStudio:\nFigure 1.1: Panes RStudio\nSource\nwrite codes, like save.\nbasic extension codes .R, possibility (cover later). save code later use, can open script also simple text editor (like Notepad), since plain text. hit enter code wont executed, just simply start new line. want run code hit ctrl + enter execute single line, ctrl+shift+enter execute full script.\nSourceWe write codes, like save.\nbasic extension codes .R, possibility (cover later). save code later use, can open script also simple text editor (like Notepad), since plain text. hit enter code wont executed, just simply start new line. want run code hit ctrl + enter execute single line, ctrl+shift+enter execute full script.Console\nfind executed codes, response . example, type 2 + 2 hit enter, R execute expression, response 4.\nConsoleHere find executed codes, response . example, type 2 + 2 hit enter, R execute expression, response 4.Help\ncan use pane familier function. example, want know input can specify using mean, can type ?mean console, use search field pane. description function presented pane. (pane super useful exam)\nHelpYou can use pane familier function. example, want know input can specify using mean, can type ?mean console, use search field pane. description function presented pane. (pane super useful exam)HistoryHistoryFiles\ncan see list files current working directory. Working directory folder, R want currently read files. want import dataset, just click file pane.\nhighly recommend set project folder class later job. means , R creates folder puts .Rproj file . can always click .Rproj file return unfinished work. can customise R put variables environtent left last time, history used codes, see data copy + paste folder.\nFilesYou can see list files current working directory. Working directory folder, R want currently read files. want import dataset, just click file pane.highly recommend set project folder class later job. means , R creates folder puts .Rproj file . can always click .Rproj file return unfinished work. can customise R put variables environtent left last time, history used codes, see data copy + paste folder.PlotsPlotsPackages\ncan install packages pane. need given package, click install, start typing name. , activate packages time open R library(eurostat) command. can also use function package just simly type eurostat::get_eurostat().\nPackagesYou can install packages pane. need given package, click install, start typing name. , activate packages time open R library(eurostat) command. can also use function package just simly type eurostat::get_eurostat().Environment\ncan see list variables already created. example can type x = 3 console. Now x variable appear environment pane, can check value type x console. can also save variables .RData data format wish.\nEnvironmentHere can see list variables already created. example can type x = 3 console. Now x variable appear environment pane, can check value type x console. can also save variables .RData data format wish.ViewerViewer","code":"\n2 + 2\n#> [1] 4"},{"path":"seminar1.html","id":"data-types","chapter":"1 Introduction to R","heading":"1.4 Data types","text":"Lets see first, kind datatypes exist R. Lets assign variable called x., type x? can use class command answer .numeric1. means can use +, -, * operators .Lets see types.character, basically can contain kind letter, digits, white space.logical value. can TRUE FALSE","code":"\nx <- 4\nclass(x)\n#> [1] \"numeric\"\ny <- \"blue\"\nclass(y)\n#> [1] \"character\"\ndoes_it_rain <- TRUE\nclass(does_it_rain)\n#> [1] \"logical\""},{"path":"seminar1.html","id":"vectors","chapter":"1 Introduction to R","heading":"1.4.1 vectors","text":"can create vector c function. (combine)can asses given element :can use functions :can also easily create sequence syntax start:stopIf combine characters, mentiont can convert vector factor type. useful can enclose order vector want control possible values.\nLets see minimal exampleIf want sort vector, see Fourth comes right First. character vectors sorted alphabetical order. can solve factorWe can merge vectors data.frame, basically like excel table. column variable (header), row observation.NA stands “available”, values missing. times work data.frames (similarly like pandas python), important data type learn.Storing complex data, can use list. use data.frame need vectors equal length. hold, frequent case, want store collection data.frames, list perfect solution! rare issue, big panel dataset usually stored separated files (different file year, like: cis_survey2016.csv, cis_survey2017.csv). situations suggested store data list.Now mylist stores data.frame two vector. can access components [[ ]]. example, first element:","code":"\nx <- c(11, 201, 301)\nx\n#> [1]  11 201 301\nx[2]\n#> [1] 201\nsum(x)\n#> [1] 513\n1:10\n#>  [1]  1  2  3  4  5  6  7  8  9 10\nmy_vector <- c(\"First\", \"Second\", \"Third\", \"Fourth\")\nsort(my_vector)\n#> [1] \"First\"  \"Fourth\" \"Second\" \"Third\"\nmy_vector2 <- factor(my_vector, ordered = TRUE, levels = c(\"First\", \"Second\", \"Third\", \"Fourth\"))\nsort(my_vector2)\n#> [1] First  Second Third  Fourth\n#> Levels: First < Second < Third < Fourth\navengers_df <- data.frame(name = c(\"Captain America\", \"Hulk\", \"Dr. Strange\"), \n           color = c(\"blue\", \"green\", NA))\n\navengers_df\n#>              name color\n#> 1 Captain America  blue\n#> 2            Hulk green\n#> 3     Dr. Strange  <NA>\nmylist <- list(avengers_df, my_vector, x)\nmylist[[1]]\n#>              name color\n#> 1 Captain America  blue\n#> 2            Hulk green\n#> 3     Dr. Strange  <NA>"},{"path":"seminar1.html","id":"data-manipulation","chapter":"1 Introduction to R","heading":"1.5 Data manipulation","text":"","code":""},{"path":"seminar1.html","id":"data-import","chapter":"1 Introduction to R","heading":"1.5.1 Import data into R","text":"mentioned formely easiest way import data click files pane. However, manual step useful import analyse data , probably want use data next time well. way good idea copy paste code importing data script.\nFigure 1.2: Import csv data R\nfact, data working directory, can refer “relative referencing”. means type name file, full path, R automatically start look file working directory2.Now imported tidy dataset. column variable, row observation. Lets see select specific data . want analyse one column , can use $ operator.output pizza character vector currently, answers contain letters. options :Using .numeric function force R using values numerical data.got warning message. letters appear R convert values numbers, values became NA (Available) values.Remove letters answers convert vector correct datatype.manage , use syntax called regular expressions. want show 4 expressions now function. function gsub detect given letter character replace something. Lets see !can use last example solve problem.","code":"\nlibrary(readr)\ndf <- read_delim(\"da_q.csv\", delim = \";\", escape_double = FALSE, trim_ws = TRUE)\ndf <- read_delim(str_c(WD, \"/data/da_q.csv\"), delim = \";\", escape_double = FALSE, trim_ws = TRUE)\npizza <- df$`How many slices of pizza can you it at once?`\n\npizza\n#>  [1] \"8\"                                                         \n#>  [2] \"12\"                                                        \n#>  [3] \"Depends on size. Can be up to 5 slices of the medium pizza\"\n#>  [4] \"2\"                                                         \n#>  [5] \"3\"                                                         \n#>  [6] \"4\"                                                         \n#>  [7] \"4\"                                                         \n#>  [8] \"4\"                                                         \n#>  [9] \"3\"                                                         \n#> [10] \"2\"                                                         \n#> [11] \"4\"                                                         \n#> [12] \"3\"                                                         \n#> [13] \"3\"                                                         \n#> [14] \"2\"                                                         \n#> [15] \"2\"                                                         \n#> [16] \"4 and It depends how much I am hungry\"                     \n#> [17] \"4\"                                                         \n#> [18] \"3\"                                                         \n#> [19] \"2\"                                                         \n#> [20] \"6\"                                                         \n#> [21] \"3\"\nas.numeric(pizza)\n#> Warning: NAs introduced by coercion\n#>  [1]  8 12 NA  2  3  4  4  4  3  2  4  3  3  2  2 NA  4  3  2  6  3\ngsub(x = \"Awesome 12\", pattern = \"\\\\w\", replacement = \"B\") # every non-white space\n#> [1] \"BBBBBBB BB\"\ngsub(x = \"Awesome 12\", pattern = \"\\\\s\", replacement = \"B\") # every white space\n#> [1] \"AwesomeB12\"\ngsub(x = \"Awesome 12\", pattern = \"\\\\d\", replacement = \"B\") # every digit\n#> [1] \"Awesome BB\"\ngsub(x = \"Awesome 12\", pattern = \"\\\\D\", replacement = \"B\") # every non-digit value\n#> [1] \"BBBBBBBB12\"\npizza_only_digits <- gsub(x = pizza, pattern = \"\\\\D\", replacement = \"\") \n\npizza_only_digits\n#>  [1] \"8\"  \"12\" \"5\"  \"2\"  \"3\"  \"4\"  \"4\"  \"4\"  \"3\"  \"2\"  \"4\"  \"3\"  \"3\"  \"2\"  \"2\" \n#> [16] \"4\"  \"4\"  \"3\"  \"2\"  \"6\"  \"3\"\n\nas.numeric(pizza_only_digits)\n#>  [1]  8 12  5  2  3  4  4  4  3  2  4  3  3  2  2  4  4  3  2  6  3"},{"path":"seminar1.html","id":"conditional-statements","chapter":"1 Introduction to R","heading":"1.6 Conditional statements","text":"offen use conditional statement programming. clean concept: condition TRUE, evaluate following task.want write else statement R, highly recomment use snippet . Snippet means, type press shift + tab, R automaticly write framework use:condition use logical value input, condition. can use conditions following operators: <, >, <=, >=, ==, !=, .na, %%, stringr::str_detect().can also specify task R , statement false.","code":"\nif (condition) {\n  \n}\n4 < 5\n#> [1] TRUE\n5 <= 5\n#> [1] TRUE\n4 > 5\n#> [1] FALSE\n5 >=4\n#> [1] TRUE\n2 == 3 # equal?\n#> [1] FALSE\n(2 + 2) == 4\n#> [1] TRUE\n(2 + 2) != 4 # not equal?\n#> [1] FALSE\n3 != 3\n#> [1] FALSE\nis.na(4)\n#> [1] FALSE\nis.na(NA)\n#> [1] TRUE\n3 %in% c(1, 2, 3)\n#> [1] TRUE\nstringr::str_detect(string = \"this function is awesome!\", pattern = \"some\")\n#> [1] TRUE\nstringr::str_detect(string = \"this function is awesome!\", pattern = \"none\")\n#> [1] FALSE\nif (2>3) {\n  print(\"Print this\")\n} else {\n  print(\"Print that\")\n}\n#> [1] \"Print that\""},{"path":"seminar1.html","id":"loops","chapter":"1 Introduction to R","heading":"1.7 Loops","text":"","code":""},{"path":"seminar1.html","id":"while","chapter":"1 Introduction to R","heading":"1.7.1 While","text":"can also use loop specify task R condition TRUE.","code":"\nx <- 1\n\nwhile (x < 15) {\n  cat(paste0(x, \"^2=\")) # cat = print, just into the same line\n  cat(x^2)\n  cat(\"\\n\") # force R to create a new line\n  x <- x + 1 # if you miss this step then R will repeat the task infinit times\n}\n#> 1^2=1\n#> 2^2=4\n#> 3^2=9\n#> 4^2=16\n#> 5^2=25\n#> 6^2=36\n#> 7^2=49\n#> 8^2=64\n#> 9^2=81\n#> 10^2=100\n#> 11^2=121\n#> 12^2=144\n#> 13^2=169\n#> 14^2=196"},{"path":"seminar1.html","id":"for","chapter":"1 Introduction to R","heading":"1.7.2 For","text":"framewrok can specify task, R x times. example, print message 10 times.can use inside { parenthesis.","code":"\nfor (i in 1:10) {\n  print(\"You R amazing!\")\n}\n#> [1] \"You R amazing!\"\n#> [1] \"You R amazing!\"\n#> [1] \"You R amazing!\"\n#> [1] \"You R amazing!\"\n#> [1] \"You R amazing!\"\n#> [1] \"You R amazing!\"\n#> [1] \"You R amazing!\"\n#> [1] \"You R amazing!\"\n#> [1] \"You R amazing!\"\n#> [1] \"You R amazing!\"\nfor (i in 1:5) {\n  print(i)\n}\n#> [1] 1\n#> [1] 2\n#> [1] 3\n#> [1] 4\n#> [1] 5"},{"path":"seminar1.html","id":"functions","chapter":"1 Introduction to R","heading":"1.8 Functions","text":"offen work functions R, can also write . use function word specify input variables.","code":"\nmy_first_function <- function(x) {\n  # removed all non-digit characters from x, and take the squared of it.\n  as.numeric(gsub(x, pattern = \"\\\\D\", replacement = \"\"))^2\n}\n\nmy_first_function(\"Depends on, maybe 5 slices\")\n#> [1] 25"},{"path":"seminar1.html","id":"apply-family","chapter":"1 Introduction to R","heading":"1.9 Apply family","text":"family contains 3 functions, want show (complex ones, covered bookdown).function apply tells R use function row column data.frame. frist argument data.frame, third function shoul use second margin:\n- margin = 2: apply given function COLUMNS\n- margin = 1: apply given function ROWSNumber numeric answers quetions:Number numeric answers participant:Lapply similar list objects.interested number observation (length) vector:output still list. sapply solution want convert vector.","code":"\nnon_na <- function(x) {\n  # how many numeric observation are in the vector\n  sum(!is.na(as.numeric(x)))\n}\napply(df, 2, non_na)\n#>                                                                                ID \n#>                                                                                21 \n#>                    What is your zodiac? (https://www.astrology-zodiac-signs.com/) \n#>                                                                                 0 \n#>                                                       Do you prefer dogs or cats? \n#>                                                                                 0 \n#>                             What experiences do have on related to R programming? \n#>                                                                                 0 \n#>                                      How many slices of pizza can you it at once? \n#>                                                                                19 \n#>                                                             Do you wear glasses?2 \n#>                                                                                 0 \n#>                                       How many countries have you been to so far? \n#>                                                                                21 \n#>   How many instagram followers do you have? (zero, if you do not have an account) \n#>                                                                                20 \n#>                                        How many brothers and sisters do you have? \n#>                                                                                19 \n#>                              What is your batteries current charge level? (0-100) \n#>                                                                                19 \n#> What is the traditional food in your country? (you can mention more, if you wish) \n#>                                                                                 0\napply(df, 1, non_na)\n#>  [1] 6 6 4 5 6 6 6 6 6 6 5 6 6 6 6 4 6 6 6 6 5\nmylist <- list(\n  first_vector = c(1, 2, 3),\n  second_vector = letters # built in character vector, contains all the letters\n)\n\nmylist\n#> $first_vector\n#> [1] 1 2 3\n#> \n#> $second_vector\n#>  [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n#> [20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\nout <- lapply(mylist, length)\n\nout\n#> $first_vector\n#> [1] 3\n#> \n#> $second_vector\n#> [1] 26\n\nclass(out)\n#> [1] \"list\"\nsapply(mylist, length)\n#>  first_vector second_vector \n#>             3            26"},{"path":"seminar2.html","id":"seminar2","chapter":"2 Markdown & Tidyverse","heading":"2 Markdown & Tidyverse","text":"","code":""},{"path":"seminar2.html","id":"markdown","chapter":"2 Markdown & Tidyverse","heading":"2.1 Markdown","text":"Last week wrote codes Source pane, save codes revisit file file explorer, can see extension file .R. can open file text editor (like Notepad) see codes. .R file can write codes comments, hit ctrl + shift + enter lines evaluated. times goal use .R files , want reuse codes frequently (like downloading data website).Another possible extension files .Rmd, stands R MarkDown. file format can combine text, R codes output one single document. now, use RMarkdown class. Please visit following website find useful examples: https://rmarkdown.rstudio.com/articles_intro.html","code":""},{"path":"seminar2.html","id":"introduction-to-the-tidyverse","chapter":"2 Markdown & Tidyverse","heading":"2.2 Introduction to the tidyverse","text":"work tidyverse today. can simply install CRAN (go Packages pane click install button). tidyverse simple package. “tidyverse set packages work harmony share common data representations […]”Tidyverse contains important packages ’re likely use everyday data analyses:ggplot2, data visualisation.ggplot2, data visualisation.dplyr, data manipulation.dplyr, data manipulation.tidyr, data tidying.tidyr, data tidying.readr, data import.readr, data import.purrr, functional programming.purrr, functional programming.tibble, tibbles, modern re-imagining data frames.tibble, tibbles, modern re-imagining data frames.stringr, strings.stringr, strings.forcats, factors.forcats, factors.installed packages, can load core packages `library` command. receive warning message, worry, fine.","code":"\nlibrary(tidyverse)"},{"path":"seminar2.html","id":"the-operator","chapter":"2 Markdown & Tidyverse","heading":"2.3 The %>% operator","text":"operator written ctrl + shift + m, denoted %>%, pronounce pipe. understand relevance, think like … . opreator forward value previous expression next function first unspecified input. Lets see example:first generate numerical vector trajectories standard normal distribution.visualize distribution histogram.\nFigure 2.1: Histogram standard normal distribution\nNow assign norm_sample object use single graph. working project confusing tons one time used objects environment (Like DataFrameAfterCleaningStep1, DataFrameAfterCleaningStep2, DataFrameAfterCleaningStep3, etc.).pipe operator can embed several steps one single workflow. way assign norm_sample object. simple generate random values draw distribution.\nFigure 2.2: Histogram standard normal distribution using pipe\nmay see title plot changed (probably graph also changed bit, since chances low generate exactly 1000 random values). pipe many tidyverse function works lambda like function framework. means can refer input value (one single input) ..Example:result 16, since 2 + 2 = 4, 4 * 4 equals 16.pipe may seem unrelevant first, one powerful tool R complex data manipulating steps. cover core functions dplyr chapter, appear following video (37:30 - 38:30), familier , see motivation behind pipe.","code":"\nnorm_sample <- rnorm(n = 1000, mean = 0, sd = 1) # standard normal\nhist(norm_sample)\nrnorm(n = 1000, mean = 0, sd = 1) %>% \n  hist()\n(2 + 2) %>% \n  {. * .}\n#> [1] 16"},{"path":"seminar2.html","id":"tibble-count-filter-select-arrange","chapter":"2 Markdown & Tidyverse","heading":"2.4 Tibble, count, filter, select, arrange","text":"","code":""},{"path":"seminar2.html","id":"tibble","chapter":"2 Markdown & Tidyverse","heading":"2.4.1 Tibble","text":"Let’s import dataset OECD webpage. Download data csv format paste working directory.read_csv importad readr package, thus shares output adequat tidyverse principles. fertility_df data.frame, tibble, means printed nicely console: first 10 rows appears, amount columns can printed without linebreak (similar pandas dataframe python).","code":"\nfertility_df <- read_csv(\"DP_LIVE_22092021161631568.csv\")\nfertility_df\n#> # A tibble: 3,193 x 8\n#>    LOCATION INDICATOR SUBJECT MEASURE   FREQUENCY  TIME Value `Flag Codes`\n#>    <chr>    <chr>     <chr>   <chr>     <chr>     <dbl> <dbl> <lgl>       \n#>  1 AUS      FERTILITY TOT     CHD_WOMAN A          1960  3.45 NA          \n#>  2 AUS      FERTILITY TOT     CHD_WOMAN A          1961  3.55 NA          \n#>  3 AUS      FERTILITY TOT     CHD_WOMAN A          1962  3.43 NA          \n#>  4 AUS      FERTILITY TOT     CHD_WOMAN A          1963  3.34 NA          \n#>  5 AUS      FERTILITY TOT     CHD_WOMAN A          1964  3.15 NA          \n#>  6 AUS      FERTILITY TOT     CHD_WOMAN A          1965  2.97 NA          \n#>  7 AUS      FERTILITY TOT     CHD_WOMAN A          1966  2.89 NA          \n#>  8 AUS      FERTILITY TOT     CHD_WOMAN A          1967  2.85 NA          \n#>  9 AUS      FERTILITY TOT     CHD_WOMAN A          1968  2.89 NA          \n#> 10 AUS      FERTILITY TOT     CHD_WOMAN A          1969  2.89 NA          \n#> # ... with 3,183 more rows"},{"path":"seminar2.html","id":"count","chapter":"2 Markdown & Tidyverse","heading":"2.4.2 Count","text":"count function can simple count number appearancesof levels given column. Example:Now can see 60 observation ARG. interested country datapoints, can use sort = TRUE option.can also use pipe [^good solution assign new dataframe count table]may specifiy multiple columns, way frequency value combinaton appears.Now see one observation country time, data frame originally tidy (usually case). Let’s see example Q GDP data OECD webpage.Using count function, may find MEASURE, SUBJECT & FREQUENCY columns multiple levels.Let’s say interested observations SUBJECT equal TOT (total), MEASURE equal PC_CHGPY (percentage change previous value) FREQUENCY equal (quarterly observations). can select rows using filter function. 1st argument dataframe want modify, arguments conditional statements. statements TRUE, row selected.Just like count, use function %>% operator, use & instead ,, wish use “”, can use | two statement.","code":"\ncount(fertility_df, LOCATION)\n#> # A tibble: 54 x 2\n#>    LOCATION     n\n#>    <chr>    <int>\n#>  1 ARG         60\n#>  2 AUS         60\n#>  3 AUT         61\n#>  4 BEL         60\n#>  5 BGR         60\n#>  6 BRA         60\n#>  7 CAN         60\n#>  8 CHE         61\n#>  9 CHL         60\n#> 10 CHN         60\n#> # ... with 44 more rows\ncount(fertility_df, LOCATION, sort = TRUE)\n#> # A tibble: 54 x 2\n#>    LOCATION     n\n#>    <chr>    <int>\n#>  1 AUT         61\n#>  2 CHE         61\n#>  3 CZE         61\n#>  4 DNK         61\n#>  5 EST         61\n#>  6 FIN         61\n#>  7 FRA         61\n#>  8 LUX         61\n#>  9 NOR         61\n#> 10 NZL         61\n#> # ... with 44 more rows\nfertility_df %>% # %>% = the 1st argument of count function is the fertility_df data.frame\n  count(LOCATION)\n#> # A tibble: 54 x 2\n#>    LOCATION     n\n#>    <chr>    <int>\n#>  1 ARG         60\n#>  2 AUS         60\n#>  3 AUT         61\n#>  4 BEL         60\n#>  5 BGR         60\n#>  6 BRA         60\n#>  7 CAN         60\n#>  8 CHE         61\n#>  9 CHL         60\n#> 10 CHN         60\n#> # ... with 44 more rows\nfertility_df %>% \n  count(LOCATION, TIME, sort = T)\n#> # A tibble: 3,193 x 3\n#>    LOCATION  TIME     n\n#>    <chr>    <dbl> <int>\n#>  1 ARG       1960     1\n#>  2 ARG       1961     1\n#>  3 ARG       1962     1\n#>  4 ARG       1963     1\n#>  5 ARG       1964     1\n#>  6 ARG       1965     1\n#>  7 ARG       1966     1\n#>  8 ARG       1967     1\n#>  9 ARG       1968     1\n#> 10 ARG       1969     1\n#> # ... with 3,183 more rows\ngdp_df <- read_csv(\"DP_LIVE_22092021163414835.csv\")\ngdp_df %>% \n  count(MEASURE, SUBJECT, FREQUENCY)\n#> # A tibble: 5 x 4\n#>   MEASURE  SUBJECT FREQUENCY     n\n#>   <chr>    <chr>   <chr>     <int>\n#> 1 IDX      VOLIDX  A          1764\n#> 2 IDX      VOLIDX  Q          7127\n#> 3 PC_CHGPP TOT     A          2329\n#> 4 PC_CHGPP TOT     Q          9472\n#> 5 PC_CHGPY TOT     Q          9385\nfilter(gdp_df, SUBJECT == \"TOT\", MEASURE == \"PC_CHGPY\", FREQUENCY != \"A\")\n#> # A tibble: 9,385 x 8\n#>    LOCATION INDICATOR SUBJECT MEASURE  FREQUENCY TIME     Value `Flag Codes`\n#>    <chr>    <chr>     <chr>   <chr>    <chr>     <chr>    <dbl> <chr>       \n#>  1 DEU      QGDP      TOT     PC_CHGPY Q         1961-Q1  7.45  E           \n#>  2 DEU      QGDP      TOT     PC_CHGPY Q         1961-Q2  5.00  E           \n#>  3 DEU      QGDP      TOT     PC_CHGPY Q         1961-Q3  3.58  E           \n#>  4 DEU      QGDP      TOT     PC_CHGPY Q         1961-Q4  3.00  E           \n#>  5 DEU      QGDP      TOT     PC_CHGPY Q         1962-Q1  3.47  E           \n#>  6 DEU      QGDP      TOT     PC_CHGPY Q         1962-Q2  5.11  E           \n#>  7 DEU      QGDP      TOT     PC_CHGPY Q         1962-Q3  5.47  E           \n#>  8 DEU      QGDP      TOT     PC_CHGPY Q         1962-Q4  4.76  E           \n#>  9 DEU      QGDP      TOT     PC_CHGPY Q         1963-Q1 -0.372 E           \n#> 10 DEU      QGDP      TOT     PC_CHGPY Q         1963-Q2  3.02  E           \n#> # ... with 9,375 more rows\ngdp_df %>% \n  filter(SUBJECT == \"TOT\" & MEASURE == \"PC_CHGPY\" & FREQUENCY != \"A\")\n#> # A tibble: 9,385 x 8\n#>    LOCATION INDICATOR SUBJECT MEASURE  FREQUENCY TIME     Value `Flag Codes`\n#>    <chr>    <chr>     <chr>   <chr>    <chr>     <chr>    <dbl> <chr>       \n#>  1 DEU      QGDP      TOT     PC_CHGPY Q         1961-Q1  7.45  E           \n#>  2 DEU      QGDP      TOT     PC_CHGPY Q         1961-Q2  5.00  E           \n#>  3 DEU      QGDP      TOT     PC_CHGPY Q         1961-Q3  3.58  E           \n#>  4 DEU      QGDP      TOT     PC_CHGPY Q         1961-Q4  3.00  E           \n#>  5 DEU      QGDP      TOT     PC_CHGPY Q         1962-Q1  3.47  E           \n#>  6 DEU      QGDP      TOT     PC_CHGPY Q         1962-Q2  5.11  E           \n#>  7 DEU      QGDP      TOT     PC_CHGPY Q         1962-Q3  5.47  E           \n#>  8 DEU      QGDP      TOT     PC_CHGPY Q         1962-Q4  4.76  E           \n#>  9 DEU      QGDP      TOT     PC_CHGPY Q         1963-Q1 -0.372 E           \n#> 10 DEU      QGDP      TOT     PC_CHGPY Q         1963-Q2  3.02  E           \n#> # ... with 9,375 more rows"},{"path":"seminar2.html","id":"mutate","chapter":"2 Markdown & Tidyverse","heading":"2.4.3 Mutate","text":"gdp_df dataframe can find TIME column class character. Lets say want change date. Functions related date lubridate package. Since values TIME column consist year quarter, use yq function change date. forget work datapoints FREQUENCY annual. let’s keep previous filter. want modify given column dataframe use mutate function. pipe operator now combine filter mutate command.Now TIME already date column, can add additional condition: want analyze latest valuse (value TIME maximum).Let’s find highest values. change order rows arrange function. want set decreasing order, put columns name desc command.want remove unused columns. can select columns select function.Alternative notation select:","code":"\ngdp_df %>% \n  filter(SUBJECT == \"TOT\" & MEASURE == \"PC_CHGPY\" & FREQUENCY != \"A\") %>% \n  mutate(TIME = lubridate::yq(TIME))\n#> # A tibble: 9,385 x 8\n#>    LOCATION INDICATOR SUBJECT MEASURE  FREQUENCY TIME        Value `Flag Codes`\n#>    <chr>    <chr>     <chr>   <chr>    <chr>     <date>      <dbl> <chr>       \n#>  1 DEU      QGDP      TOT     PC_CHGPY Q         1961-01-01  7.45  E           \n#>  2 DEU      QGDP      TOT     PC_CHGPY Q         1961-04-01  5.00  E           \n#>  3 DEU      QGDP      TOT     PC_CHGPY Q         1961-07-01  3.58  E           \n#>  4 DEU      QGDP      TOT     PC_CHGPY Q         1961-10-01  3.00  E           \n#>  5 DEU      QGDP      TOT     PC_CHGPY Q         1962-01-01  3.47  E           \n#>  6 DEU      QGDP      TOT     PC_CHGPY Q         1962-04-01  5.11  E           \n#>  7 DEU      QGDP      TOT     PC_CHGPY Q         1962-07-01  5.47  E           \n#>  8 DEU      QGDP      TOT     PC_CHGPY Q         1962-10-01  4.76  E           \n#>  9 DEU      QGDP      TOT     PC_CHGPY Q         1963-01-01 -0.372 E           \n#> 10 DEU      QGDP      TOT     PC_CHGPY Q         1963-04-01  3.02  E           \n#> # ... with 9,375 more rows\ngdp_df %>% \n  filter(SUBJECT == \"TOT\" & MEASURE == \"PC_CHGPY\" & FREQUENCY != \"A\") %>% \n  mutate(TIME = lubridate::yq(TIME)) %>% \n  filter(TIME == max(TIME)) \n#> # A tibble: 49 x 8\n#>    LOCATION INDICATOR SUBJECT MEASURE  FREQUENCY TIME       Value `Flag Codes`\n#>    <chr>    <chr>     <chr>   <chr>    <chr>     <date>     <dbl> <chr>       \n#>  1 DEU      QGDP      TOT     PC_CHGPY Q         2021-04-01  9.41 P           \n#>  2 IND      QGDP      TOT     PC_CHGPY Q         2021-04-01 20.9  <NA>        \n#>  3 TUR      QGDP      TOT     PC_CHGPY Q         2021-04-01 21.4  <NA>        \n#>  4 IDN      QGDP      TOT     PC_CHGPY Q         2021-04-01  7.19 <NA>        \n#>  5 LVA      QGDP      TOT     PC_CHGPY Q         2021-04-01 10.8  <NA>        \n#>  6 CZE      QGDP      TOT     PC_CHGPY Q         2021-04-01  8.18 <NA>        \n#>  7 BRA      QGDP      TOT     PC_CHGPY Q         2021-04-01 12.4  <NA>        \n#>  8 POL      QGDP      TOT     PC_CHGPY Q         2021-04-01 11.0  <NA>        \n#>  9 MEX      QGDP      TOT     PC_CHGPY Q         2021-04-01 19.5  P           \n#> 10 CAN      QGDP      TOT     PC_CHGPY Q         2021-04-01 12.7  <NA>        \n#> # ... with 39 more rows\ngdp_df %>% \n  filter(SUBJECT == \"TOT\" & MEASURE == \"PC_CHGPY\" & FREQUENCY != \"A\") %>% \n  mutate(TIME = lubridate::yq(TIME)) %>% \n  filter(TIME == max(TIME)) %>%\n  arrange(desc(Value)) \n#> # A tibble: 49 x 8\n#>    LOCATION INDICATOR SUBJECT MEASURE  FREQUENCY TIME       Value `Flag Codes`\n#>    <chr>    <chr>     <chr>   <chr>    <chr>     <date>     <dbl> <chr>       \n#>  1 GBR      QGDP      TOT     PC_CHGPY Q         2021-04-01  22.2 <NA>        \n#>  2 TUR      QGDP      TOT     PC_CHGPY Q         2021-04-01  21.4 <NA>        \n#>  3 IRL      QGDP      TOT     PC_CHGPY Q         2021-04-01  21.1 <NA>        \n#>  4 IND      QGDP      TOT     PC_CHGPY Q         2021-04-01  20.9 <NA>        \n#>  5 ESP      QGDP      TOT     PC_CHGPY Q         2021-04-01  19.8 P           \n#>  6 MEX      QGDP      TOT     PC_CHGPY Q         2021-04-01  19.5 P           \n#>  7 FRA      QGDP      TOT     PC_CHGPY Q         2021-04-01  18.7 <NA>        \n#>  8 HUN      QGDP      TOT     PC_CHGPY Q         2021-04-01  17.7 <NA>        \n#>  9 NZL      QGDP      TOT     PC_CHGPY Q         2021-04-01  17.4 <NA>        \n#> 10 ITA      QGDP      TOT     PC_CHGPY Q         2021-04-01  17.3 <NA>        \n#> # ... with 39 more rows\ngdp_df %>% \n  filter(SUBJECT == \"TOT\" & MEASURE == \"PC_CHGPY\" & FREQUENCY != \"A\") %>% \n  mutate(TIME = lubridate::yq(TIME)) %>% \n  filter(TIME == max(TIME)) %>% \n  arrange(desc(Value)) %>% \n  select(geo = LOCATION, gdp_change = Value) # select the LOCATION & gdp_change columns\n#> # A tibble: 49 x 2\n#>    geo   gdp_change\n#>    <chr>      <dbl>\n#>  1 GBR         22.2\n#>  2 TUR         21.4\n#>  3 IRL         21.1\n#>  4 IND         20.9\n#>  5 ESP         19.8\n#>  6 MEX         19.5\n#>  7 FRA         18.7\n#>  8 HUN         17.7\n#>  9 NZL         17.4\n#> 10 ITA         17.3\n#> # ... with 39 more rows\ngdp_df %>% \n  select(1) # select the 1st column\n#> # A tibble: 30,077 x 1\n#>    LOCATION\n#>    <chr>   \n#>  1 OECD    \n#>  2 OECD    \n#>  3 OECD    \n#>  4 OECD    \n#>  5 OECD    \n#>  6 OECD    \n#>  7 OECD    \n#>  8 OECD    \n#>  9 OECD    \n#> 10 OECD    \n#> # ... with 30,067 more rows\n\ngdp_df %>% \n  select(-1) # omit the 1st column\n#> # A tibble: 30,077 x 7\n#>    INDICATOR SUBJECT MEASURE  FREQUENCY TIME  Value `Flag Codes`\n#>    <chr>     <chr>   <chr>    <chr>     <chr> <dbl> <chr>       \n#>  1 QGDP      TOT     PC_CHGPP A         1962   5.70 <NA>        \n#>  2 QGDP      TOT     PC_CHGPP A         1963   5.20 <NA>        \n#>  3 QGDP      TOT     PC_CHGPP A         1964   6.38 <NA>        \n#>  4 QGDP      TOT     PC_CHGPP A         1965   5.35 <NA>        \n#>  5 QGDP      TOT     PC_CHGPP A         1966   5.75 <NA>        \n#>  6 QGDP      TOT     PC_CHGPP A         1967   3.96 <NA>        \n#>  7 QGDP      TOT     PC_CHGPP A         1968   5.92 <NA>        \n#>  8 QGDP      TOT     PC_CHGPP A         1969   5.57 <NA>        \n#>  9 QGDP      TOT     PC_CHGPP A         1970   3.94 <NA>        \n#> 10 QGDP      TOT     PC_CHGPP A         1971   3.70 <NA>        \n#> # ... with 30,067 more rows\n\ngdp_df %>% \n  select(1:2) # select all the columns between the 1st and the 2nd\n#> # A tibble: 30,077 x 2\n#>    LOCATION INDICATOR\n#>    <chr>    <chr>    \n#>  1 OECD     QGDP     \n#>  2 OECD     QGDP     \n#>  3 OECD     QGDP     \n#>  4 OECD     QGDP     \n#>  5 OECD     QGDP     \n#>  6 OECD     QGDP     \n#>  7 OECD     QGDP     \n#>  8 OECD     QGDP     \n#>  9 OECD     QGDP     \n#> 10 OECD     QGDP     \n#> # ... with 30,067 more rows\n\ngdp_df %>% \n  select(LOCATION:TIME) # select all the columns between the LOCATION and the TIME column\n#> # A tibble: 30,077 x 6\n#>    LOCATION INDICATOR SUBJECT MEASURE  FREQUENCY TIME \n#>    <chr>    <chr>     <chr>   <chr>    <chr>     <chr>\n#>  1 OECD     QGDP      TOT     PC_CHGPP A         1962 \n#>  2 OECD     QGDP      TOT     PC_CHGPP A         1963 \n#>  3 OECD     QGDP      TOT     PC_CHGPP A         1964 \n#>  4 OECD     QGDP      TOT     PC_CHGPP A         1965 \n#>  5 OECD     QGDP      TOT     PC_CHGPP A         1966 \n#>  6 OECD     QGDP      TOT     PC_CHGPP A         1967 \n#>  7 OECD     QGDP      TOT     PC_CHGPP A         1968 \n#>  8 OECD     QGDP      TOT     PC_CHGPP A         1969 \n#>  9 OECD     QGDP      TOT     PC_CHGPP A         1970 \n#> 10 OECD     QGDP      TOT     PC_CHGPP A         1971 \n#> # ... with 30,067 more rows\n\ngdp_df %>% \n  select(TIME, LOCATION, everything()) \n#> # A tibble: 30,077 x 8\n#>    TIME  LOCATION INDICATOR SUBJECT MEASURE  FREQUENCY Value `Flag Codes`\n#>    <chr> <chr>    <chr>     <chr>   <chr>    <chr>     <dbl> <chr>       \n#>  1 1962  OECD     QGDP      TOT     PC_CHGPP A          5.70 <NA>        \n#>  2 1963  OECD     QGDP      TOT     PC_CHGPP A          5.20 <NA>        \n#>  3 1964  OECD     QGDP      TOT     PC_CHGPP A          6.38 <NA>        \n#>  4 1965  OECD     QGDP      TOT     PC_CHGPP A          5.35 <NA>        \n#>  5 1966  OECD     QGDP      TOT     PC_CHGPP A          5.75 <NA>        \n#>  6 1967  OECD     QGDP      TOT     PC_CHGPP A          3.96 <NA>        \n#>  7 1968  OECD     QGDP      TOT     PC_CHGPP A          5.92 <NA>        \n#>  8 1969  OECD     QGDP      TOT     PC_CHGPP A          5.57 <NA>        \n#>  9 1970  OECD     QGDP      TOT     PC_CHGPP A          3.94 <NA>        \n#> 10 1971  OECD     QGDP      TOT     PC_CHGPP A          3.70 <NA>        \n#> # ... with 30,067 more rows\n  # select all the columns, but TIME & LOCATION to the first place"},{"path":"seminar2.html","id":"group_by-summary","chapter":"2 Markdown & Tidyverse","heading":"2.5 Group_by, Summary","text":"Let’s see another source data. can easily access Eurostat tables eurostat package.Let’s choose “Live births mother’s age NUTS 2 region” dataset.First , interested NUTS 2 reginal data. dataset national aggregated values also published (geo codes length 2 characters). Let’s remove .also remove aggregated values keep latest one.Now dataset clean: one observation geo age category. Let’s suppose interested total number birth mothers age EU (know found table ). want sum values values column age category.","code":"\neurostat::search_eurostat(\"birth\")\n#> # A tibble: 284 x 8\n#>    title   code  type  `last update of~ `last table str~ `data start` `data end`\n#>    <chr>   <chr> <chr> <chr>            <chr>            <chr>        <chr>     \n#>  1 Live b~ demo~ data~ 30.06.2021       23.02.2021       1990         2019      \n#>  2 Live b~ demo~ data~ 01.07.2021       01.07.2021       2013         2019      \n#>  3 Live b~ demo~ data~ 30.06.2021       23.02.2021       1990         2019      \n#>  4 Popula~ cens~ data~ 26.08.2015       08.02.2021       2011         2011      \n#>  5 Popula~ cens~ data~ 26.08.2015       08.02.2021       2011         2011      \n#>  6 Popula~ cens~ data~ 26.08.2015       08.02.2021       2011         2011      \n#>  7 Popula~ cens~ data~ 26.08.2015       08.02.2021       2011         2011      \n#>  8 Popula~ cens~ data~ 26.08.2015       08.02.2021       2011         2011      \n#>  9 Popula~ lfst~ data~ 10.09.2021       27.04.2021       1999         2020      \n#> 10 Activi~ lfst~ data~ 10.09.2021       27.04.2021       1999         2020      \n#> # ... with 274 more rows, and 1 more variable: values <chr>\nlivebirth_eu_df <- eurostat::get_eurostat(\"demo_r_fagec\")\n\nlivebirth_eu_df\n#> # A tibble: 456,956 x 5\n#>    unit  age   geo   time       values\n#>    <chr> <chr> <chr> <date>      <dbl>\n#>  1 NR    TOTAL AL    2019-01-01  28561\n#>  2 NR    TOTAL AL0   2019-01-01  28438\n#>  3 NR    TOTAL AL01  2019-01-01   8909\n#>  4 NR    TOTAL AL02  2019-01-01  12089\n#>  5 NR    TOTAL AL03  2019-01-01   7440\n#>  6 NR    TOTAL ALX   2019-01-01    123\n#>  7 NR    TOTAL ALXX  2019-01-01    123\n#>  8 NR    TOTAL AT    2019-01-01  84952\n#>  9 NR    TOTAL AT1   2019-01-01  36819\n#> 10 NR    TOTAL AT11  2019-01-01   2232\n#> # ... with 456,946 more rows\nlivebirth_eu_df %>% \n  filter(str_length(geo) != 2)\n#> # A tibble: 416,961 x 5\n#>    unit  age   geo   time       values\n#>    <chr> <chr> <chr> <date>      <dbl>\n#>  1 NR    TOTAL AL0   2019-01-01  28438\n#>  2 NR    TOTAL AL01  2019-01-01   8909\n#>  3 NR    TOTAL AL02  2019-01-01  12089\n#>  4 NR    TOTAL AL03  2019-01-01   7440\n#>  5 NR    TOTAL ALX   2019-01-01    123\n#>  6 NR    TOTAL ALXX  2019-01-01    123\n#>  7 NR    TOTAL AT1   2019-01-01  36819\n#>  8 NR    TOTAL AT11  2019-01-01   2232\n#>  9 NR    TOTAL AT12  2019-01-01  14652\n#> 10 NR    TOTAL AT13  2019-01-01  19935\n#> # ... with 416,951 more rows\nlivebirth_eu_df %>% \n  filter(str_length(geo) != 2) %>% \n  filter(age != \"TOTAL\" & time == \"2019-01-01\") %>% \n  filter(!(age %in% c(\"UNK\", \"Y_GE45\", \"Y_GE48\", \"Y_GE50\", \"Y_LT16\")))\n#> # A tibble: 14,309 x 5\n#>    unit  age    geo   time       values\n#>    <chr> <chr>  <chr> <date>      <dbl>\n#>  1 NR    Y10-14 AL0   2019-01-01     24\n#>  2 NR    Y10-14 AL01  2019-01-01      4\n#>  3 NR    Y10-14 AL02  2019-01-01     13\n#>  4 NR    Y10-14 AL03  2019-01-01      7\n#>  5 NR    Y10-14 ALX   2019-01-01      0\n#>  6 NR    Y10-14 ALXX  2019-01-01      0\n#>  7 NR    Y10-14 AT1   2019-01-01      1\n#>  8 NR    Y10-14 AT11  2019-01-01      0\n#>  9 NR    Y10-14 AT12  2019-01-01      0\n#> 10 NR    Y10-14 AT13  2019-01-01      1\n#> # ... with 14,299 more rows\nlivebirth_eu_df %>% \n  filter(str_length(geo) != 2) %>% \n  filter(age != \"TOTAL\" & time == \"2019-01-01\") %>% \n  filter(!(age %in% c(\"UNK\", \"Y_GE45\", \"Y_GE48\", \"Y_GE50\", \"Y_LT16\"))) %>% \n  group_by(age) %>%\n  summarise(values = sum(values))"},{"path":"seminar2.html","id":"pivot-longerwider","chapter":"2 Markdown & Tidyverse","heading":"2.6 Pivot longer/wider","text":"Let’s assume interested growth rate fertility country. First, write function calculate growth rates (chain index).Example:(hided rest table)problem comes GrowthRate AUT 1960, since now (check table):\\[\\text{Growth}_{\\text{AUT}, 1960} = \\frac{\\text{AUS}_{2019}}{\\text{AUT}_{1960}}\\]can easily solve transforming structure table. need make table wider case, pivot_wider. function create new column level seleceted variable.use chain_index function now columns, can avoid previous bug. can use function columns (except first) mutate_at function.now let’s transform table original structure. can pivot_longer column.","code":"\nchain_index <- function(x) {\n  scales::percent(x/lag(x)-1, accuracy = .01)\n  # lag: previous observation\n}\nx <- c(100, 107, 105, 110)\n\nchain_index(x)\n#> [1] NA       \"7.00%\"  \"-1.87%\" \"4.76%\"\nfertility_df %>% \n  select(LOCATION, TIME, Value) %>% \n  mutate(GrowthRate = chain_index(Value))\nfertility_df %>% \n  select(geo = LOCATION, time = TIME, fertility = Value) %>% \n  pivot_wider(names_from = \"geo\", values_from = \"fertility\")\n#> # A tibble: 61 x 55\n#>     time   AUS   AUT   BEL   CAN   CZE   DNK   FIN   FRA   DEU   GRC   HUN   ISL\n#>    <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n#>  1  1960  3.45  2.69  2.54  3.9   2.11  2.54  2.71  2.74  2.37  2.23  2.02  4.26\n#>  2  1961  3.55  2.78  2.63  3.84  2.13  2.55  2.65  2.82  2.44  2.13  1.94  3.88\n#>  3  1962  3.43  2.8   2.59  3.76  2.14  2.54  2.66  2.8   2.44  2.16  1.79  3.98\n#>  4  1963  3.34  2.82  2.68  3.67  2.33  2.64  2.66  2.9   2.51  2.14  1.82  3.98\n#>  5  1964  3.15  2.79  2.72  3.5   2.36  2.6   2.58  2.91  2.53  2.24  1.8   3.86\n#>  6  1965  2.97  2.7   2.62  3.15  2.18  2.61  2.46  2.85  2.5   2.25  1.81  3.71\n#>  7  1966  2.89  2.66  2.52  2.81  2.01  2.62  2.4   2.8   2.51  2.32  1.88  3.58\n#>  8  1967  2.85  2.62  2.41  2.6   1.9   2.35  2.32  2.67  2.45  2.45  2.01  3.28\n#>  9  1968  2.89  2.58  2.31  2.45  1.83  2.12  2.15  2.59  2.36  2.42  2.06  3.07\n#> 10  1969  2.89  2.49  2.28  2.4   1.86  2     1.94  2.53  2.21  2.36  2.04  2.99\n#> # ... with 51 more rows, and 42 more variables: IRL <dbl>, ITA <dbl>,\n#> #   JPN <dbl>, KOR <dbl>, LUX <dbl>, MEX <dbl>, NLD <dbl>, NZL <dbl>,\n#> #   NOR <dbl>, POL <dbl>, PRT <dbl>, SVK <dbl>, ESP <dbl>, SWE <dbl>,\n#> #   CHE <dbl>, TUR <dbl>, GBR <dbl>, USA <dbl>, BRA <dbl>, CHL <dbl>,\n#> #   CHN <dbl>, EST <dbl>, IND <dbl>, IDN <dbl>, ISR <dbl>, RUS <dbl>,\n#> #   SVN <dbl>, ZAF <dbl>, COL <dbl>, LVA <dbl>, LTU <dbl>, ARG <dbl>,\n#> #   BGR <dbl>, HRV <dbl>, CYP <dbl>, MLT <dbl>, ROU <dbl>, SAU <dbl>, ...\nfertility_df %>% \n  select(geo = LOCATION, time = TIME, fertility = Value) %>% \n  pivot_wider(names_from = \"geo\", values_from = \"fertility\") %>% \n  mutate_at(-1, chain_index)\n#> # A tibble: 61 x 55\n#>     time AUS   AUT   BEL   CAN   CZE   DNK   FIN   FRA   DEU   GRC   HUN   ISL  \n#>    <dbl> <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr>\n#>  1  1960 <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA> \n#>  2  1961 2.90% 3.35% 3.54% -1.5~ 0.95% 0.39% -2.2~ 2.92% 2.95% -4.4~ -3.9~ -8.9~\n#>  3  1962 -3.3~ 0.72% -1.5~ -2.0~ 0.47% -0.3~ 0.38% -0.7~ 0.00% 1.41% -7.7~ 2.58%\n#>  4  1963 -2.6~ 0.71% 3.47% -2.3~ 8.88% 3.94% 0.00% 3.57% 2.87% -0.9~ 1.68% 0.00%\n#>  5  1964 -5.6~ -1.0~ 1.49% -4.6~ 1.29% -1.5~ -3.0~ 0.34% 0.80% 4.67% -1.1~ -3.0~\n#>  6  1965 -5.7~ -3.2~ -3.6~ -10.~ -7.6~ 0.38% -4.6~ -2.0~ -1.1~ 0.45% 0.56% -3.8~\n#>  7  1966 -2.6~ -1.4~ -3.8~ -10.~ -7.8~ 0.38% -2.4~ -1.7~ 0.40% 3.11% 3.87% -3.5~\n#>  8  1967 -1.3~ -1.5~ -4.3~ -7.4~ -5.4~ -10.~ -3.3~ -4.6~ -2.3~ 5.60% 6.91% -8.3~\n#>  9  1968 1.40% -1.5~ -4.1~ -5.7~ -3.6~ -9.7~ -7.3~ -3.0~ -3.6~ -1.2~ 2.49% -6.4~\n#> 10  1969 0.00% -3.4~ -1.3~ -2.0~ 1.64% -5.6~ -9.7~ -2.3~ -6.3~ -2.4~ -0.9~ -2.6~\n#> # ... with 51 more rows, and 42 more variables: IRL <chr>, ITA <chr>,\n#> #   JPN <chr>, KOR <chr>, LUX <chr>, MEX <chr>, NLD <chr>, NZL <chr>,\n#> #   NOR <chr>, POL <chr>, PRT <chr>, SVK <chr>, ESP <chr>, SWE <chr>,\n#> #   CHE <chr>, TUR <chr>, GBR <chr>, USA <chr>, BRA <chr>, CHL <chr>,\n#> #   CHN <chr>, EST <chr>, IND <chr>, IDN <chr>, ISR <chr>, RUS <chr>,\n#> #   SVN <chr>, ZAF <chr>, COL <chr>, LVA <chr>, LTU <chr>, ARG <chr>,\n#> #   BGR <chr>, HRV <chr>, CYP <chr>, MLT <chr>, ROU <chr>, SAU <chr>, ...\nfertility_df %>% \n  select(geo = LOCATION, time = TIME, fertility = Value) %>% \n  pivot_wider(names_from = \"geo\", values_from = \"fertility\") %>% \n  mutate_at(-1, chain_index) %>% \n  pivot_longer(-1, names_to = \"geo\", values_to = \"fertility\")\n#> # A tibble: 3,294 x 3\n#>     time geo   fertility\n#>    <dbl> <chr> <chr>    \n#>  1  1960 AUS   <NA>     \n#>  2  1960 AUT   <NA>     \n#>  3  1960 BEL   <NA>     \n#>  4  1960 CAN   <NA>     \n#>  5  1960 CZE   <NA>     \n#>  6  1960 DNK   <NA>     \n#>  7  1960 FIN   <NA>     \n#>  8  1960 FRA   <NA>     \n#>  9  1960 DEU   <NA>     \n#> 10  1960 GRC   <NA>     \n#> # ... with 3,284 more rows"},{"path":"seminar2.html","id":"group_modify","chapter":"2 Markdown & Tidyverse","heading":"2.7 Group_modify","text":"Alternativly, solve problem split data frame 63 individual data frames (one country). use following syntax, get correct results:","code":"\nfertility_df %>% \n  select(geo = LOCATION, time = TIME, fertility = Value) %>% \n  arrange(time) %>% \n  group_by(geo) %>% \n  group_modify(~ mutate(.x, fertility_growth = chain_index(fertility)), .keep = F)"},{"path":"seminar2.html","id":"exercise","chapter":"2 Markdown & Tidyverse","heading":"2.8 Exercise","text":"get know classmates solve exercise.Create new .Rmd fileCreate new .Rmd fileImport da_q.csv data R relative referencing (see Chapter 1.5.1)Import da_q.csv data R relative referencing (see Chapter 1.5.1)Write information know least 3 teammates (Names neccesary) text .Rmd.Write information know least 3 teammates (Names neccesary) text .Rmd.Write R codes find teammates (write also comments code3) using base R function (tools learned 1st seminar).Write R codes find teammates (write also comments code3) using base R function (tools learned 1st seminar).Write R codes find teammates using dplyr function (tools learned 2nd seminar)Write R codes find teammates using dplyr function (tools learned 2nd seminar)found teammate output R code correct ID number person.Example:Hungary, national food Hungary gulash.ID number 1.course, can choose . :)","code":"\ndf\n#> # A tibble: 21 x 11\n#>       ID `What is your zod~ `Do you prefer ~ `What experience~ `How many slices~\n#>    <dbl> <chr>              <chr>            <chr>             <chr>            \n#>  1     1 leo                dogs             I am familier wi~ 8                \n#>  2     2 taurus             Dogd             I have some expe~ 12               \n#>  3     3 pisces             Both             I do not have an~ Depends on size.~\n#>  4     4 taurus             neither          I do not have an~ 2                \n#>  5     5 aquarius           dogs             I have some expe~ 3                \n#>  6     6 leo                Cats             I am familier wi~ 4                \n#>  7     7 virgo              Cats             I am familier wi~ 4                \n#>  8     8 virgo              Dogs             I learnt R in un~ 4                \n#>  9     9 taurus             dogs             I learnt R in un~ 3                \n#> 10    10 cancer             dogs             I do not have an~ 2                \n#> # ... with 11 more rows, and 6 more variables: Do you wear glasses?2 <chr>,\n#> #   How many countries have you been to so far? <dbl>,\n#> #   How many instagram followers do you have? (zero, if you do not have an account) <chr>,\n#> #   How many brothers and sisters do you have? <chr>,\n#> #   What is your batteries current charge level? (0-100) <chr>,\n#> #   What is the traditional food in your country? (you can mention more, if you wish) <chr>\ndf %>% \n  filter(str_detect(`What is the traditional food in your country? (you can mention more, if you wish)`, \"gulash\")) %>% \n  pull(ID)\n#> [1] 1"},{"path":"seminar3.html","id":"seminar3","chapter":"3 Ggplot","heading":"3 Ggplot","text":"","code":""},{"path":"seminar3.html","id":"motivation-for-ggplot","chapter":"3 Ggplot","heading":"3.1 Motivation for GGplot","text":"Although can use base R [including diagrams made plot command ], rarely recommended, except simplicity. Instead, might want use ggplot2, , although complex base R, almost upper limit customizability.addition nicer graphics, much important reason use ggplot. package named Leland Wilkinsons work Gramar Graphics (hence gg), essential structure ideal graphing algorithm formulated. Since ggplot2 follows principles, see many things keep mind, everything makes sense . mastered material (reading ) able make necessary diagrams[^personal opinion creating simple complex plots best way understand data make others watch research.].","code":""},{"path":"seminar3.html","id":"intorduction-to-ggplot","chapter":"3 Ggplot","heading":"3.2 Intorduction to ggplot","text":"Ggplot2 can installed standalone, package part “package collection” called tidyverse. highly recommend always start session loading tidyverse, since collection contains many crucial function data analyses. Thus, depending whether package already downloaded, install install.packages (\"tidyverse\") first time use tidyverse computer, load packages library(tidyverse)[^Grading homework usually see type install.packages script leave . probably worst habbit can R programming. way install packages everytime use script. Remember, add library(tidyverse) first line code, use install.packages.].ggplot2 get additional data tables, sake simplicity now use diamonds . Let’s take look structure nameplate:Lets see first plot ggplot.\nFigure 3.1: first plot ggplot.\ntypical syntax creating plot ggplot. plot consist 3 parts:ggplot function two inputs: data use (mapping)ggplot function two inputs: data use (mapping)aesthetics: offen inserted ggplot function (mapping argument). code means values depth columns x-axis values price column y-axisaesthetics: offen inserted ggplot function (mapping argument). code means values depth columns x-axis values price column y-axisgeom: specifies plot type, currently create point graph (scatter plot). Type geom hit TAB see possibilities.geom: specifies plot type, currently create point graph (scatter plot). Type geom hit TAB see possibilities.many options customise plot. First, lets see can change inside geom function.","code":"\nlibrary(tidyverse)\ndiamonds\n#> # A tibble: 53,940 x 10\n#>    carat cut       color clarity depth table price     x     y     z\n#>    <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n#>  1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n#>  2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n#>  3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n#>  4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n#>  5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n#>  6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n#>  7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n#>  8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n#>  9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n#> 10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n#> # ... with 53,930 more rows\nggplot(data = diamonds, mapping = aes(x = depth, y = price)) + \n  geom_point()"},{"path":"seminar3.html","id":"color","chapter":"3 Ggplot","heading":"3.2.1 Color","text":"\nFigure 3.2: Changing color points blue.\n","code":"\nggplot(data = diamonds, mapping = aes(x = depth, y = price)) + \n  geom_point(color = \"blue\")"},{"path":"seminar3.html","id":"size","chapter":"3 Ggplot","heading":"3.2.2 Size","text":"\nFigure 3.3: Changing size points.\n","code":"\nggplot(data = diamonds, mapping = aes(x = depth, y = price)) + \n  geom_point(size = 5)"},{"path":"seminar3.html","id":"shape","chapter":"3 Ggplot","heading":"3.2.3 Shape","text":"geom functions shape argument, geom_point . can modify shape type.\nFigure 3.4: Changing shape.\nimportant default shape type color argument. want border points change shape 21.","code":"\nggplot(data = diamonds, mapping = aes(x = depth, y = price)) + \n  geom_point(shape = 3) # change the shape of the points\nggplot(data = diamonds, mapping = aes(x = depth, y = price)) + \n  geom_point(shape = 21, color = \"blue\", fill = \"red\")"},{"path":"seminar3.html","id":"aesthetics","chapter":"3 Ggplot","heading":"3.2.4 Aesthetics","text":"examples used color, size shape arguments explicit way inside geom function. want add different colors based cut column different shape (usually required academic papers). add argument mapping aes function.Everything x y aes function appears legend. can omit adding show.legend = FALSE:","code":"\nggplot(data = diamonds, mapping = aes(x = depth, y = price, color = cut, shape = cut))  +\n  geom_point()\nggplot(data = diamonds, mapping = aes(x = depth, y = price, color = cut, shape = cut))  +\n  geom_point(show.legend = FALSE) # hide legend"},{"path":"seminar3.html","id":"customizing","chapter":"3 Ggplot","heading":"3.3 customizing","text":"use scale_ functions specify colors plot . academic work must often use greyscale colors:also add labels plot labs function:use theme customizing plot looks.available themes recommend:\nFigure 3.5: Themes ggplot\ncan install packages find even themes, like {ggdark} dark themes. also add options example:want use theme, can make default:","code":"\nggplot(data = diamonds, mapping = aes(x = depth, y = price, color = cut, shape = cut))  +\n  geom_point() +\n  scale_color_grey() # using greyscale colors\nggplot(data = diamonds, mapping = aes(x = depth, y = price, color = cut))  +\n  geom_point() +\n  labs(\n    x = \"Depth\",\n    y = \"Price in dollar\",\n    title = \"My awesome title\",\n    color = \"My legend title\",\n    subtitle = \"My awesome subtitle\",\n    caption = \"Details about the source.\"\n  )\nggplot(data = diamonds, mapping = aes(x = depth, y = price, color = cut, shape = cut))  +\n  geom_point() + \n  theme_minimal() + # theme with white backgroung and no axis line\n  theme(\n    axis.text = element_text(size = 30) # increase text size to unreasonable high\n  )\nggplot(data = diamonds) + \n  aes(x = depth, y = price, color = cut) + \n  geom_point() + \n  labs(x = \"X-axis\", y = \"Y-axis\", \n       title = \"Nice title\", \n       color = \"New legend title\",\n       subtitle = \"Unknown years\") + \n  scale_x_continuous(labels = function(x) str_c(x, \"%\"), # percentage on x-axis\n                     limits = c(50, 70), \n                     expand = c(0, 0) # axis line at the last observation\n                     ) + \n  scale_color_manual( # modify colors\n    values = c(\"red\", \"blue\", \"orange\", \"green\", \"grey\")\n    ) +\n  ggdark::dark_theme_classic() + # dark theme\n  theme(plot.title = element_text(color = \"red\", face = \"bold\")) # change title style\ntheme_set(theme_minimal())\nggplot(diamonds, aes(depth, price)) +\n  geom_point()"},{"path":"seminar3.html","id":"geom","chapter":"3 Ggplot","heading":"3.4 Geom","text":"Lets see type charts exist. univariate continues data recommend density, histogram boxplot.\nFigure 3.6: Density plot\n\nFigure 3.7: Histogram\n\nFigure 3.8: Boxplot\nsee boxplot?\nFigure 3.9: Structure boxplot\ninterested outlier, plan remove , good idea use base R boxplot function.\nFigure 3.10: Boxplot basea R command.\nfunction advantage. Lets assign output bplot_output instead simply plot , turning plot argument FALSE.bplot_output element named . contains values observations outliers based boxplot. can simply check given observation vector , remove observation [^always complicated real life tasks, fine now.]. Lets create function step.univariate discrete variables can use column chart. two options :geom_bar: just specify discrete variable want use, number observations returned category.geom_bar: just specify discrete variable want use, number observations returned category.geom_col: Add discrete variable categories continues variable corresponding values. calculate number observation initial step.geom_col: Add discrete variable categories continues variable corresponding values. calculate number observation initial step.\nFigure 3.11: Geom_bar\n\nFigure 3.12: Geom_col\ncan also use geom_bar two categorical variables:\nFigure 3.13: Bar chart fill argument.\nproportions:\nFigure 3.14: Position_fill\nkind matrix can use geom_tile creating heatmaps. Lets see correlations!\nFigure 3.15: Heatmap\nLets see time-series data. need data Eurostat.Lets merge two data.frames time geo column.\nFigure 3.16: Time-series plot\n\nFigure 3.17: Two variables two geom_line command\nneed legend:\nFigure 3.18: Two time-series variables pivot_longer create legend.\nAlternatively, can put two variables x y-axis show time label. famous figure named Beveridge-curve (learn macroeconomics course).\nFigure 3.19: Beveridge-curve\n","code":"\nggplot(diamonds, aes(price)) + \n  geom_density(color = \"red\", fill = \"yellow\")\nggplot(diamonds, aes(price)) +\n  geom_histogram() + \n  scale_x_log10()\nggplot(diamonds, aes(price)) +\n  geom_boxplot()\nboxplot(diamonds$price)\nbplot_output <- boxplot(diamonds$price, plot = FALSE) # hide the plot\nbplot_output\n#> $stats\n#>         [,1]\n#> [1,]   326.0\n#> [2,]   950.0\n#> [3,]  2401.0\n#> [4,]  5324.5\n#> [5,] 11886.0\n#> \n#> $n\n#> [1] 53940\n#> \n#> $conf\n#>         [,1]\n#> [1,] 2371.24\n#> [2,] 2430.76\n#> \n#> $out\n#>    [1] 11888 11888 11888 11897 11899 11899 11901 11903 11904 11905 11906 11912\n#>   [13] 11913 11917 11917 11921 11922 11923 11923 11923 11924 11925 11926 11927\n#>   [25] 11927 11933 11934 11935 11939 11942 11943 11946 11946 11946 11946 11948\n#>   [37] 11948 11950 11951 11954 11955 11956 11957 11957 11957 11958 11962 11963\n#>   [49] 11965 11966 11966 11967 11968 11968 11969 11970 11971 11971 11973 11975\n#>   [61] 11975 11975 11976 11979 11982 11985 11986 11988 11988 11988 11988 11990\n#>   [73] 11998 11999 12000 12004 12005 12008 12009 12012 12013 12014 12016 12021\n#>   [85] 12028 12030 12030 12030 12030 12030 12030 12031 12032 12035 12036 12038\n#>   [97] 12044 12047 12047 12048 12048 12048 12048 12052 12053 12055 12058 12059\n#>  [109] 12060 12061 12061 12063 12063 12066 12068 12069 12071 12071 12071 12075\n#>  [121] 12078 12078 12079 12081 12081 12082 12084 12084 12084 12085 12085 12087\n#>  [133] 12089 12092 12093 12094 12094 12095 12095 12098 12098 12098 12099 12099\n#>  [145] 12100 12100 12100 12100 12105 12108 12108 12109 12111 12112 12117 12119\n#>  [157] 12121 12121 12123 12127 12140 12141 12146 12148 12148 12150 12150 12151\n#>  [169] 12152 12152 12152 12153 12154 12155 12156 12156 12157 12161 12165 12168\n#>  [181] 12168 12168 12170 12171 12174 12175 12179 12179 12179 12179 12182 12182\n#>  [193] 12183 12185 12186 12190 12193 12195 12196 12196 12196 12196 12196 12196\n#>  [205] 12196 12199 12200 12202 12206 12207 12207 12209 12209 12209 12209 12210\n#>  [217] 12210 12210 12210 12210 12215 12215 12219 12220 12221 12224 12224 12224\n#>  [229] 12225 12226 12226 12228 12228 12229 12229 12230 12231 12232 12236 12237\n#>  [241] 12238 12238 12242 12244 12244 12247 12248 12252 12253 12255 12257 12257\n#>  [253] 12257 12260 12261 12261 12261 12261 12265 12267 12268 12268 12269 12271\n#>  [265] 12271 12271 12273 12282 12283 12284 12284 12285 12286 12288 12291 12291\n#>  [277] 12295 12295 12297 12300 12304 12305 12308 12308 12308 12308 12308 12308\n#>  [289] 12308 12308 12308 12311 12311 12314 12315 12316 12317 12319 12319 12320\n#>  [301] 12321 12327 12327 12332 12334 12336 12336 12338 12338 12338 12338 12338\n#>  [313] 12339 12341 12342 12342 12342 12342 12342 12342 12343 12345 12349 12356\n#>  [325] 12359 12360 12361 12361 12364 12364 12369 12369 12369 12369 12373 12375\n#>  [337] 12377 12377 12377 12378 12378 12379 12379 12380 12380 12381 12386 12386\n#>  [349] 12388 12389 12390 12392 12392 12392 12392 12394 12394 12396 12400 12401\n#>  [361] 12401 12401 12401 12403 12406 12407 12407 12409 12415 12416 12416 12417\n#>  [373] 12417 12418 12423 12423 12423 12429 12430 12431 12431 12432 12433 12437\n#>  [385] 12437 12440 12440 12443 12447 12450 12451 12454 12454 12454 12455 12458\n#>  [397] 12458 12459 12459 12459 12462 12465 12466 12467 12467 12468 12468 12474\n#>  [409] 12477 12483 12485 12489 12490 12492 12492 12493 12494 12494 12495 12498\n#>  [421] 12499 12499 12499 12500 12502 12506 12508 12509 12512 12515 12521 12522\n#>  [433] 12526 12529 12530 12530 12531 12531 12539 12539 12541 12542 12543 12545\n#>  [445] 12545 12545 12546 12547 12547 12549 12551 12551 12551 12551 12554 12554\n#>  [457] 12554 12554 12554 12554 12555 12556 12559 12561 12565 12566 12571 12573\n#>  [469] 12576 12576 12576 12581 12581 12581 12584 12587 12587 12587 12591 12592\n#>  [481] 12592 12596 12598 12602 12603 12605 12606 12606 12607 12607 12608 12610\n#>  [493] 12610 12612 12613 12614 12615 12616 12616 12617 12617 12617 12617 12618\n#>  [505] 12620 12621 12621 12621 12622 12622 12626 12629 12631 12633 12633 12637\n#>  [517] 12639 12641 12641 12642 12644 12644 12645 12646 12647 12648 12648 12648\n#>  [529] 12654 12654 12654 12654 12655 12655 12655 12657 12670 12671 12671 12672\n#>  [541] 12674 12674 12677 12677 12680 12680 12681 12681 12681 12681 12683 12686\n#>  [553] 12687 12688 12690 12693 12693 12696 12696 12696 12697 12698 12700 12702\n#>  [565] 12707 12707 12709 12712 12713 12713 12714 12716 12717 12717 12717 12720\n#>  [577] 12720 12722 12723 12725 12725 12730 12731 12734 12736 12736 12737 12737\n#>  [589] 12738 12738 12738 12738 12738 12743 12744 12745 12747 12748 12753 12754\n#>  [601] 12755 12755 12756 12756 12756 12756 12762 12764 12765 12765 12766 12768\n#>  [613] 12770 12770 12771 12773 12776 12778 12779 12779 12779 12787 12787 12787\n#>  [625] 12787 12787 12787 12788 12791 12791 12792 12794 12795 12798 12798 12799\n#>  [637] 12799 12800 12800 12809 12810 12811 12812 12814 12816 12818 12821 12821\n#>  [649] 12821 12822 12823 12823 12823 12825 12825 12828 12829 12829 12829 12829\n#>  [661] 12829 12830 12831 12831 12832 12832 12833 12839 12840 12840 12841 12842\n#>  [673] 12843 12844 12844 12845 12846 12846 12848 12848 12851 12853 12857 12857\n#>  [685] 12862 12862 12864 12865 12870 12870 12871 12872 12872 12872 12872 12874\n#>  [697] 12874 12880 12883 12883 12884 12891 12891 12895 12896 12897 12898 12899\n#>  [709] 12900 12905 12906 12906 12907 12907 12907 12907 12907 12910 12912 12915\n#>  [721] 12916 12918 12921 12923 12927 12929 12931 12931 12932 12937 12939 12939\n#>  [733] 12940 12943 12944 12945 12947 12948 12948 12951 12956 12956 12958 12958\n#>  [745] 12958 12961 12963 12964 12967 12968 12968 12968 12970 12970 12971 12978\n#>  [757] 12978 12979 12980 12981 12981 12981 12985 12985 12985 12987 12988 12989\n#>  [769] 12990 12991 12992 12992 12996 12996 12998 12998 13001 13001 13003 13006\n#>  [781] 13006 13007 13007 13007 13009 13010 13012 13014 13015 13016 13026 13027\n#>  [793] 13029 13034 13034 13034 13034 13037 13037 13037 13038 13043 13046 13047\n#>  [805] 13047 13049 13052 13060 13060 13061 13063 13063 13063 13065 13065 13068\n#>  [817] 13068 13068 13069 13069 13074 13075 13077 13078 13079 13080 13081 13084\n#>  [829] 13085 13088 13092 13092 13095 13096 13097 13097 13098 13099 13102 13104\n#>  [841] 13107 13109 13109 13109 13110 13111 13112 13113 13115 13117 13117 13119\n#>  [853] 13119 13120 13122 13127 13132 13132 13133 13134 13134 13134 13135 13135\n#>  [865] 13135 13140 13144 13148 13152 13153 13154 13155 13156 13157 13157 13160\n#>  [877] 13161 13162 13162 13163 13165 13168 13169 13171 13177 13178 13178 13182\n#>  [889] 13182 13182 13182 13187 13189 13190 13194 13194 13196 13196 13198 13199\n#>  [901] 13200 13200 13201 13203 13203 13205 13206 13206 13207 13211 13212 13214\n#>  [913] 13215 13219 13221 13221 13225 13228 13228 13228 13229 13229 13229 13230\n#>  [925] 13232 13233 13234 13239 13242 13247 13248 13248 13248 13248 13250 13250\n#>  [937] 13250 13253 13253 13254 13254 13256 13257 13261 13263 13263 13267 13275\n#>  [949] 13275 13278 13278 13278 13280 13282 13284 13286 13287 13287 13287 13288\n#>  [961] 13289 13291 13292 13293 13298 13298 13298 13298 13299 13307 13307 13312\n#>  [973] 13316 13317 13317 13317 13320 13320 13320 13320 13320 13321 13323 13324\n#>  [985] 13325 13325 13326 13329 13329 13329 13333 13334 13337 13338 13340 13342\n#>  [997] 13344 13348 13351 13355 13355 13357 13360 13363 13363 13365 13367 13367\n#> [1009] 13369 13369 13369 13370 13370 13372 13373 13375 13376 13377 13378 13379\n#> [1021] 13387 13387 13387 13387 13389 13393 13395 13397 13398 13398 13399 13400\n#> [1033] 13400 13403 13405 13406 13417 13420 13420 13421 13421 13423 13427 13428\n#> [1045] 13434 13437 13439 13442 13445 13445 13445 13445 13453 13453 13460 13462\n#> [1057] 13462 13464 13464 13465 13474 13474 13477 13477 13480 13483 13485 13485\n#> [1069] 13485 13486 13488 13495 13498 13499 13499 13499 13500 13500 13500 13502\n#> [1081] 13503 13506 13506 13508 13512 13513 13515 13528 13530 13530 13531 13532\n#> [1093] 13536 13537 13539 13540 13542 13542 13542 13543 13544 13550 13552 13553\n#> [1105] 13553 13553 13554 13554 13555 13556 13557 13560 13561 13563 13564 13572\n#> [1117] 13574 13574 13578 13579 13582 13587 13587 13587 13587 13588 13588 13588\n#> [1129] 13595 13595 13596 13596 13596 13597 13597 13598 13598 13599 13600 13603\n#> [1141] 13605 13606 13607 13609 13609 13609 13610 13615 13619 13621 13622 13622\n#> [1153] 13622 13622 13623 13623 13624 13626 13629 13629 13630 13631 13632 13638\n#> [1165] 13642 13642 13645 13646 13653 13653 13653 13654 13655 13659 13660 13661\n#> [1177] 13665 13666 13667 13669 13671 13675 13675 13675 13677 13678 13680 13681\n#> [1189] 13686 13686 13687 13691 13691 13693 13701 13701 13702 13703 13703 13710\n#> [1201] 13711 13711 13713 13714 13719 13720 13720 13720 13720 13721 13724 13725\n#> [1213] 13726 13728 13730 13731 13732 13733 13734 13735 13736 13737 13737 13744\n#> [1225] 13744 13746 13752 13753 13755 13756 13757 13757 13757 13760 13761 13761\n#> [1237] 13764 13764 13766 13767 13768 13768 13769 13771 13771 13777 13777 13779\n#> [1249] 13782 13782 13784 13786 13786 13786 13787 13790 13790 13790 13794 13796\n#> [1261] 13797 13799 13800 13803 13807 13809 13811 13811 13811 13811 13811 13812\n#> [1273] 13812 13813 13818 13818 13819 13820 13820 13823 13823 13824 13825 13825\n#> [1285] 13827 13828 13828 13828 13831 13833 13839 13844 13844 13846 13846 13846\n#> [1297] 13849 13849 13850 13853 13853 13853 13853 13858 13864 13865 13867 13869\n#> [1309] 13872 13872 13873 13873 13879 13880 13882 13884 13885 13887 13892 13892\n#> [1321] 13899 13903 13903 13904 13905 13907 13908 13908 13912 13912 13917 13919\n#> [1333] 13919 13919 13919 13921 13923 13926 13929 13929 13930 13931 13933 13938\n#> [1345] 13939 13940 13942 13945 13945 13945 13945 13948 13949 13950 13951 13953\n#> [1357] 13956 13963 13963 13965 13968 13970 13976 13978 13983 13986 13986 13986\n#> [1369] 13991 13991 13993 13993 13994 13994 13995 13995 13996 13996 13998 14014\n#> [1381] 14017 14022 14024 14026 14027 14027 14028 14031 14032 14032 14033 14033\n#> [1393] 14037 14038 14039 14040 14042 14042 14042 14044 14047 14057 14058 14061\n#> [1405] 14065 14065 14066 14067 14067 14068 14071 14071 14071 14071 14071 14074\n#> [1417] 14080 14083 14084 14092 14095 14095 14103 14103 14105 14105 14105 14106\n#> [1429] 14107 14108 14111 14112 14119 14120 14125 14126 14127 14129 14130 14137\n#> [1441] 14138 14139 14146 14146 14148 14150 14154 14156 14157 14165 14165 14165\n#> [1453] 14165 14165 14167 14171 14174 14177 14179 14180 14182 14184 14185 14185\n#> [1465] 14188 14190 14192 14192 14194 14196 14199 14199 14199 14199 14199 14199\n#> [1477] 14199 14201 14205 14208 14208 14209 14211 14214 14215 14217 14220 14220\n#> [1489] 14220 14224 14224 14229 14231 14234 14234 14236 14236 14237 14238 14239\n#> [1501] 14240 14242 14242 14242 14245 14247 14247 14249 14251 14256 14256 14258\n#> [1513] 14266 14266 14267 14268 14275 14277 14277 14278 14279 14281 14282 14283\n#> [1525] 14285 14292 14293 14294 14294 14294 14294 14294 14295 14298 14299 14300\n#> [1537] 14300 14300 14300 14304 14308 14308 14308 14319 14319 14321 14323 14328\n#> [1549] 14330 14330 14334 14338 14340 14341 14341 14341 14344 14348 14350 14350\n#> [1561] 14351 14352 14354 14359 14359 14359 14361 14362 14364 14364 14368 14372\n#> [1573] 14372 14372 14375 14375 14375 14375 14383 14383 14383 14386 14386 14386\n#> [1585] 14386 14386 14388 14388 14394 14394 14395 14399 14400 14402 14403 14404\n#> [1597] 14406 14407 14408 14410 14411 14412 14414 14414 14414 14416 14416 14421\n#> [1609] 14424 14424 14426 14426 14426 14426 14428 14428 14429 14429 14430 14430\n#> [1621] 14433 14438 14444 14445 14447 14451 14452 14452 14452 14453 14456 14462\n#> [1633] 14465 14474 14476 14477 14479 14481 14482 14482 14482 14482 14482 14482\n#> [1645] 14482 14483 14486 14488 14489 14490 14494 14495 14498 14498 14500 14502\n#> [1657] 14502 14502 14502 14503 14505 14507 14507 14507 14519 14525 14527 14527\n#> [1669] 14527 14529 14534 14540 14542 14542 14542 14542 14543 14543 14544 14545\n#> [1681] 14548 14556 14558 14558 14558 14561 14565 14574 14574 14577 14578 14579\n#> [1693] 14581 14581 14581 14584 14586 14588 14592 14593 14593 14593 14597 14603\n#> [1705] 14603 14603 14605 14611 14615 14616 14616 14618 14620 14623 14624 14625\n#> [1717] 14626 14634 14637 14637 14637 14638 14639 14646 14646 14648 14650 14652\n#> [1729] 14654 14654 14659 14660 14660 14662 14663 14666 14666 14667 14673 14674\n#> [1741] 14674 14674 14674 14675 14680 14683 14687 14691 14691 14692 14698 14699\n#> [1753] 14704 14709 14709 14709 14709 14711 14715 14715 14717 14719 14720 14724\n#> [1765] 14725 14725 14727 14731 14732 14733 14735 14737 14740 14744 14745 14745\n#> [1777] 14749 14749 14750 14750 14752 14759 14763 14763 14766 14768 14773 14775\n#> [1789] 14775 14775 14775 14775 14777 14779 14787 14787 14790 14790 14792 14795\n#> [1801] 14799 14801 14802 14803 14810 14811 14812 14813 14814 14817 14819 14824\n#> [1813] 14826 14830 14833 14837 14837 14838 14841 14842 14842 14844 14844 14844\n#> [1825] 14844 14847 14853 14855 14857 14859 14860 14863 14866 14867 14870 14882\n#> [1837] 14888 14889 14889 14889 14892 14893 14900 14904 14904 14915 14918 14918\n#> [1849] 14918 14918 14920 14925 14931 14933 14935 14936 14936 14937 14938 14939\n#> [1861] 14945 14947 14948 14948 14949 14952 14956 14957 14959 14961 14968 14968\n#> [1873] 14970 14973 14973 14975 14976 14982 14982 14982 14998 14998 15000 15002\n#> [1885] 15005 15007 15011 15013 15014 15014 15017 15022 15025 15025 15025 15025\n#> [1897] 15026 15030 15030 15031 15032 15032 15035 15035 15036 15038 15043 15046\n#> [1909] 15047 15052 15053 15055 15059 15064 15064 15065 15065 15067 15072 15073\n#> [1921] 15076 15079 15081 15081 15081 15083 15086 15091 15092 15092 15092 15093\n#> [1933] 15095 15096 15097 15100 15102 15102 15105 15105 15105 15109 15110 15110\n#> [1945] 15111 15116 15118 15119 15122 15124 15126 15132 15134 15134 15137 15140\n#> [1957] 15140 15143 15144 15145 15147 15147 15148 15151 15152 15153 15153 15162\n#> [1969] 15164 15164 15164 15166 15169 15169 15172 15175 15178 15184 15185 15185\n#> [1981] 15185 15188 15188 15189 15193 15197 15197 15198 15201 15210 15210 15214\n#> [1993] 15217 15217 15218 15219 15223 15223 15225 15226 15229 15231 15231 15231\n#> [2005] 15235 15238 15238 15239 15240 15241 15245 15246 15246 15247 15247 15248\n#> [2017] 15249 15249 15252 15253 15254 15255 15255 15258 15258 15259 15261 15265\n#> [2029] 15272 15275 15278 15281 15281 15282 15282 15287 15288 15291 15291 15291\n#> [2041] 15291 15293 15301 15303 15303 15306 15308 15309 15312 15312 15316 15316\n#> [2053] 15318 15320 15321 15322 15323 15323 15324 15330 15334 15334 15335 15338\n#> [2065] 15339 15339 15348 15351 15354 15364 15365 15365 15366 15370 15371 15375\n#> [2077] 15377 15378 15379 15384 15385 15386 15392 15393 15393 15394 15394 15394\n#> [2089] 15395 15395 15395 15397 15398 15404 15412 15413 15415 15415 15418 15420\n#> [2101] 15420 15424 15426 15426 15426 15428 15430 15433 15440 15444 15444 15446\n#> [2113] 15450 15451 15451 15451 15454 15458 15460 15461 15464 15465 15466 15467\n#> [2125] 15472 15474 15475 15475 15478 15485 15485 15486 15488 15494 15497 15498\n#> [2137] 15499 15505 15505 15508 15509 15510 15511 15512 15513 15515 15517 15520\n#> [2149] 15522 15528 15528 15528 15529 15530 15531 15535 15540 15540 15543 15544\n#> [2161] 15559 15562 15562 15562 15563 15568 15575 15579 15581 15584 15584 15584\n#> [2173] 15585 15587 15589 15592 15594 15600 15601 15602 15606 15606 15609 15609\n#> [2185] 15613 15615 15618 15618 15618 15619 15627 15646 15647 15649 15649 15651\n#> [2197] 15651 15651 15653 15654 15658 15662 15665 15666 15671 15671 15673 15675\n#> [2209] 15680 15683 15684 15686 15688 15690 15691 15694 15695 15696 15697 15701\n#> [2221] 15706 15707 15708 15708 15710 15714 15716 15717 15718 15721 15729 15729\n#> [2233] 15729 15729 15730 15740 15745 15745 15746 15751 15751 15756 15757 15760\n#> [2245] 15760 15760 15762 15765 15766 15767 15769 15773 15773 15773 15776 15776\n#> [2257] 15783 15785 15785 15788 15792 15792 15792 15792 15794 15797 15797 15801\n#> [2269] 15801 15801 15802 15802 15804 15804 15805 15805 15806 15808 15811 15813\n#> [2281] 15814 15818 15818 15819 15819 15819 15821 15823 15824 15825 15826 15826\n#> [2293] 15827 15829 15829 15832 15836 15837 15840 15840 15840 15841 15841 15842\n#> [2305] 15843 15845 15847 15847 15848 15848 15850 15851 15851 15851 15851 15851\n#> [2317] 15852 15857 15864 15873 15874 15874 15877 15878 15887 15888 15888 15889\n#> [2329] 15897 15897 15897 15898 15907 15908 15913 15915 15917 15917 15917 15919\n#> [2341] 15919 15919 15920 15922 15923 15928 15930 15930 15931 15934 15937 15938\n#> [2353] 15939 15939 15941 15941 15941 15942 15946 15948 15948 15949 15949 15952\n#> [2365] 15955 15957 15959 15959 15962 15964 15965 15966 15968 15970 15970 15974\n#> [2377] 15977 15977 15983 15984 15984 15984 15984 15987 15987 15990 15991 15992\n#> [2389] 15992 15992 15992 15992 15992 15993 15996 15996 16003 16004 16013 16018\n#> [2401] 16021 16023 16025 16031 16036 16037 16041 16043 16048 16049 16052 16055\n#> [2413] 16059 16062 16062 16064 16064 16064 16068 16068 16073 16073 16075 16077\n#> [2425] 16080 16082 16085 16086 16086 16087 16091 16092 16097 16098 16100 16104\n#> [2437] 16104 16111 16112 16112 16116 16123 16126 16128 16129 16130 16131 16137\n#> [2449] 16140 16146 16147 16148 16149 16149 16151 16169 16169 16169 16170 16171\n#> [2461] 16171 16174 16179 16181 16183 16187 16187 16188 16189 16190 16191 16192\n#> [2473] 16193 16195 16198 16198 16198 16206 16210 16215 16219 16220 16223 16224\n#> [2485] 16231 16231 16232 16234 16235 16235 16237 16239 16239 16239 16240 16240\n#> [2497] 16241 16241 16241 16242 16253 16253 16256 16256 16261 16262 16273 16274\n#> [2509] 16277 16278 16280 16280 16286 16287 16287 16287 16290 16291 16294 16294\n#> [2521] 16295 16297 16300 16300 16304 16304 16304 16309 16309 16311 16314 16316\n#> [2533] 16316 16316 16319 16319 16319 16323 16329 16336 16337 16339 16340 16340\n#> [2545] 16343 16353 16353 16357 16357 16358 16363 16364 16364 16368 16369 16370\n#> [2557] 16378 16380 16383 16384 16386 16389 16390 16392 16392 16395 16397 16397\n#> [2569] 16398 16400 16402 16404 16406 16407 16407 16409 16410 16412 16420 16422\n#> [2581] 16425 16426 16427 16427 16427 16431 16437 16439 16442 16446 16450 16451\n#> [2593] 16459 16462 16462 16465 16466 16466 16469 16472 16479 16479 16483 16484\n#> [2605] 16485 16492 16499 16499 16505 16506 16506 16507 16512 16512 16513 16518\n#> [2617] 16519 16520 16521 16530 16532 16533 16538 16544 16544 16545 16547 16547\n#> [2629] 16551 16558 16558 16558 16560 16562 16564 16565 16570 16575 16575 16580\n#> [2641] 16582 16582 16583 16587 16589 16592 16593 16599 16601 16603 16611 16613\n#> [2653] 16616 16617 16618 16624 16626 16626 16626 16626 16628 16628 16629 16629\n#> [2665] 16629 16632 16636 16641 16642 16643 16643 16650 16650 16650 16656 16657\n#> [2677] 16665 16669 16670 16677 16683 16687 16687 16688 16689 16690 16693 16694\n#> [2689] 16694 16700 16703 16704 16704 16707 16709 16709 16709 16715 16716 16716\n#> [2701] 16716 16717 16718 16718 16723 16723 16728 16731 16733 16733 16733 16733\n#> [2713] 16733 16733 16736 16737 16742 16747 16750 16754 16768 16769 16776 16776\n#> [2725] 16778 16778 16778 16778 16778 16778 16778 16779 16779 16779 16783 16783\n#> [2737] 16783 16783 16786 16787 16789 16789 16789 16790 16791 16792 16793 16793\n#> [2749] 16797 16800 16801 16803 16804 16805 16807 16808 16811 16813 16817 16819\n#> [2761] 16820 16823 16824 16826 16842 16842 16854 16857 16861 16872 16872 16874\n#> [2773] 16878 16879 16881 16881 16889 16896 16900 16900 16900 16901 16904 16914\n#> [2785] 16914 16914 16914 16915 16916 16921 16922 16929 16931 16934 16937 16941\n#> [2797] 16942 16944 16945 16948 16954 16955 16955 16956 16956 16957 16960 16960\n#> [2809] 16960 16969 16970 16970 16975 16985 16985 16987 16988 16992 16994 16996\n#> [2821] 17000 17001 17003 17005 17006 17009 17010 17012 17014 17016 17017 17019\n#> [2833] 17024 17024 17027 17028 17028 17028 17029 17036 17038 17039 17041 17042\n#> [2845] 17045 17045 17049 17049 17050 17051 17051 17052 17053 17057 17057 17062\n#> [2857] 17063 17065 17066 17068 17068 17068 17068 17068 17073 17073 17076 17078\n#> [2869] 17079 17081 17084 17094 17095 17095 17096 17099 17100 17103 17108 17111\n#> [2881] 17114 17114 17115 17116 17118 17123 17125 17126 17127 17136 17138 17141\n#> [2893] 17143 17143 17146 17149 17151 17153 17153 17156 17160 17162 17164 17166\n#> [2905] 17168 17168 17172 17172 17175 17176 17179 17179 17182 17184 17186 17191\n#> [2917] 17191 17192 17193 17193 17194 17197 17197 17203 17203 17204 17204 17206\n#> [2929] 17209 17209 17213 17214 17216 17218 17219 17219 17220 17221 17223 17224\n#> [2941] 17227 17228 17231 17233 17235 17235 17237 17240 17244 17245 17247 17250\n#> [2953] 17254 17256 17258 17262 17263 17263 17265 17265 17265 17267 17273 17278\n#> [2965] 17279 17294 17294 17294 17294 17297 17312 17313 17313 17315 17317 17323\n#> [2977] 17323 17327 17329 17329 17330 17334 17338 17339 17343 17347 17351 17353\n#> [2989] 17353 17357 17358 17360 17360 17365 17365 17366 17374 17377 17379 17381\n#> [3001] 17383 17392 17393 17393 17400 17403 17403 17403 17403 17405 17405 17407\n#> [3013] 17408 17414 17416 17422 17425 17433 17433 17434 17436 17441 17442 17447\n#> [3025] 17448 17449 17451 17452 17455 17458 17460 17469 17469 17472 17473 17474\n#> [3037] 17475 17476 17485 17489 17492 17492 17496 17497 17499 17504 17509 17513\n#> [3049] 17514 17515 17516 17521 17522 17523 17525 17530 17533 17534 17534 17535\n#> [3061] 17539 17545 17548 17552 17553 17554 17555 17569 17569 17570 17574 17579\n#> [3073] 17581 17582 17590 17591 17592 17595 17597 17597 17598 17600 17604 17605\n#> [3085] 17606 17607 17607 17608 17609 17614 17614 17617 17634 17640 17642 17649\n#> [3097] 17650 17658 17659 17662 17663 17666 17667 17672 17673 17673 17674 17676\n#> [3109] 17676 17685 17688 17688 17689 17689 17692 17694 17710 17712 17713 17714\n#> [3121] 17715 17716 17723 17724 17729 17730 17740 17742 17746 17747 17751 17752\n#> [3133] 17753 17759 17759 17760 17760 17760 17760 17760 17760 17761 17765 17766\n#> [3145] 17772 17773 17776 17778 17784 17798 17801 17803 17803 17804 17805 17805\n#> [3157] 17811 17816 17820 17825 17825 17826 17829 17835 17837 17838 17840 17841\n#> [3169] 17849 17849 17849 17849 17856 17864 17869 17871 17871 17877 17882 17887\n#> [3181] 17888 17889 17891 17891 17892 17892 17892 17893 17893 17893 17894 17895\n#> [3193] 17898 17902 17904 17904 17905 17909 17916 17917 17920 17923 17924 17930\n#> [3205] 17932 17934 17936 17936 17938 17949 17952 17952 17953 17955 17955 17957\n#> [3217] 17975 17983 17986 17987 17988 17989 17995 17996 17999 17999 18001 18002\n#> [3229] 18003 18005 18007 18014 18017 18018 18020 18023 18026 18026 18026 18026\n#> [3241] 18027 18027 18028 18029 18029 18034 18034 18034 18037 18041 18050 18055\n#> [3253] 18055 18057 18059 18062 18062 18066 18067 18068 18069 18071 18077 18077\n#> [3265] 18077 18077 18080 18090 18102 18104 18107 18107 18108 18112 18113 18114\n#> [3277] 18115 18115 18115 18117 18118 18119 18120 18120 18124 18124 18125 18127\n#> [3289] 18128 18128 18128 18128 18139 18139 18149 18149 18152 18153 18159 18164\n#> [3301] 18166 18168 18172 18172 18176 18178 18179 18179 18181 18183 18186 18186\n#> [3313] 18188 18188 18190 18193 18193 18193 18198 18206 18207 18207 18211 18215\n#> [3325] 18231 18231 18232 18236 18236 18236 18236 18239 18242 18242 18242 18242\n#> [3337] 18242 18251 18252 18252 18254 18255 18257 18259 18274 18275 18276 18279\n#> [3349] 18279 18281 18281 18286 18291 18293 18294 18295 18295 18296 18299 18304\n#> [3361] 18306 18308 18310 18312 18318 18318 18320 18324 18325 18325 18340 18342\n#> [3373] 18342 18343 18344 18358 18359 18363 18364 18369 18371 18371 18371 18371\n#> [3385] 18374 18374 18376 18377 18392 18394 18395 18398 18398 18398 18405 18407\n#> [3397] 18416 18419 18421 18423 18426 18426 18426 18429 18430 18430 18430 18431\n#> [3409] 18432 18435 18439 18440 18440 18442 18443 18445 18447 18447 18458 18462\n#> [3421] 18462 18468 18470 18472 18474 18475 18477 18480 18481 18483 18485 18487\n#> [3433] 18489 18493 18495 18500 18507 18507 18508 18508 18509 18515 18522 18524\n#> [3445] 18525 18526 18528 18531 18531 18532 18535 18541 18541 18542 18552 18557\n#> [3457] 18559 18559 18559 18561 18561 18565 18571 18572 18574 18575 18578 18593\n#> [3469] 18594 18598 18599 18604 18607 18611 18614 18615 18625 18630 18640 18640\n#> [3481] 18648 18653 18656 18659 18663 18674 18678 18678 18680 18682 18686 18691\n#> [3493] 18692 18692 18693 18700 18700 18701 18705 18706 18707 18709 18710 18710\n#> [3505] 18717 18718 18729 18730 18731 18735 18736 18741 18741 18741 18745 18756\n#> [3517] 18757 18759 18760 18766 18768 18777 18779 18780 18781 18784 18787 18788\n#> [3529] 18791 18791 18795 18795 18797 18803 18804 18806 18818 18823\n#> \n#> $group\n#>    [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>   [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>   [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#>  [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1555] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1592] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1629] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1666] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1703] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1740] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1777] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1814] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1851] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1888] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1925] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1962] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [1999] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2036] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2073] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2110] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2147] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2184] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2221] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2258] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2295] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2332] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2369] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2406] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2443] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2480] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2517] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2554] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2591] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2628] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2665] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2702] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2739] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2776] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2813] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2850] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2887] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2924] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2961] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [2998] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [3035] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [3072] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [3109] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [3146] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [3183] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [3220] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [3257] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [3294] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [3331] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [3368] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [3405] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [3442] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [3479] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> [3516] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#> \n#> $names\n#> [1] \"1\"\noutlier_filter <- function(x) {\noutlier_value <- boxplot(x, plot = FALSE)$out\nx %in% outlier_value # returns TRUE if the given value is an outlier\n}\ndiamonds %>% \n  filter(!outlier_filter(price)) # keep the observation if price is not an outlier\n#> # A tibble: 50,402 x 10\n#>    carat cut       color clarity depth table price     x     y     z\n#>    <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n#>  1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n#>  2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n#>  3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n#>  4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n#>  5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n#>  6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n#>  7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n#>  8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n#>  9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n#> 10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n#> # ... with 50,392 more rows\nggplot(diamonds, aes(cut)) + \n  geom_bar()\ndiamonds %>% \n  count(cut) %>% # calculating number of observations by category\n  ggplot(aes(cut, n)) + \n  geom_col()\nggplot(data = diamonds, aes(cut, fill = color))  +\n  geom_bar(color = \"black\") # color -> add border\nggplot(data = diamonds, aes(cut, fill = color))  +\n  geom_bar(color = \"black\", position = position_fill()) # fill to 100%\ndiamonds %>% \n   select_if(is.numeric) # you can calculate cor only for numerical variables\n#> # A tibble: 53,940 x 7\n#>    carat depth table price     x     y     z\n#>    <dbl> <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n#>  1  0.23  61.5    55   326  3.95  3.98  2.43\n#>  2  0.21  59.8    61   326  3.89  3.84  2.31\n#>  3  0.23  56.9    65   327  4.05  4.07  2.31\n#>  4  0.29  62.4    58   334  4.2   4.23  2.63\n#>  5  0.31  63.3    58   335  4.34  4.35  2.75\n#>  6  0.24  62.8    57   336  3.94  3.96  2.48\n#>  7  0.24  62.3    57   336  3.95  3.98  2.47\n#>  8  0.26  61.9    55   337  4.07  4.11  2.53\n#>  9  0.22  65.1    61   337  3.87  3.78  2.49\n#> 10  0.23  59.4    61   338  4     4.05  2.39\n#> # ... with 53,930 more rows\n\ndiamonds %>% \n   select_if(is.numeric) %>%  # you can calculate cor only for numerical variables\n  cor() # correlation matrix\n#>            carat       depth      table      price           x           y\n#> carat 1.00000000  0.02822431  0.1816175  0.9215913  0.97509423  0.95172220\n#> depth 0.02822431  1.00000000 -0.2957785 -0.0106474 -0.02528925 -0.02934067\n#> table 0.18161755 -0.29577852  1.0000000  0.1271339  0.19534428  0.18376015\n#> price 0.92159130 -0.01064740  0.1271339  1.0000000  0.88443516  0.86542090\n#> x     0.97509423 -0.02528925  0.1953443  0.8844352  1.00000000  0.97470148\n#> y     0.95172220 -0.02934067  0.1837601  0.8654209  0.97470148  1.00000000\n#> z     0.95338738  0.09492388  0.1509287  0.8612494  0.97077180  0.95200572\n#>                z\n#> carat 0.95338738\n#> depth 0.09492388\n#> table 0.15092869\n#> price 0.86124944\n#> x     0.97077180\n#> y     0.95200572\n#> z     1.00000000\n\ndiamonds %>% \n   select_if(is.numeric) %>%  # you can calculate cor only for numerical variables\n  cor() %>%  # correlation matrix\n  data.frame() %>% \n  rownames_to_column(var = \"X\") # make rowname to \"X\" column\n#>       X      carat       depth      table      price           x           y\n#> 1 carat 1.00000000  0.02822431  0.1816175  0.9215913  0.97509423  0.95172220\n#> 2 depth 0.02822431  1.00000000 -0.2957785 -0.0106474 -0.02528925 -0.02934067\n#> 3 table 0.18161755 -0.29577852  1.0000000  0.1271339  0.19534428  0.18376015\n#> 4 price 0.92159130 -0.01064740  0.1271339  1.0000000  0.88443516  0.86542090\n#> 5     x 0.97509423 -0.02528925  0.1953443  0.8844352  1.00000000  0.97470148\n#> 6     y 0.95172220 -0.02934067  0.1837601  0.8654209  0.97470148  1.00000000\n#> 7     z 0.95338738  0.09492388  0.1509287  0.8612494  0.97077180  0.95200572\n#>            z\n#> 1 0.95338738\n#> 2 0.09492388\n#> 3 0.15092869\n#> 4 0.86124944\n#> 5 0.97077180\n#> 6 0.95200572\n#> 7 1.00000000\n\ndiamonds %>% \n   select_if(is.numeric) %>%  # you can calculate cor only for numerical variables\n  cor() %>%  # correlation matrix\n  data.frame() %>% \n  rownames_to_column(var = \"X\") %>% \n  pivot_longer(-X, names_to = \"Y\")\n#> # A tibble: 49 x 3\n#>    X     Y       value\n#>    <chr> <chr>   <dbl>\n#>  1 carat carat  1     \n#>  2 carat depth  0.0282\n#>  3 carat table  0.182 \n#>  4 carat price  0.922 \n#>  5 carat x      0.975 \n#>  6 carat y      0.952 \n#>  7 carat z      0.953 \n#>  8 depth carat  0.0282\n#>  9 depth depth  1     \n#> 10 depth table -0.296 \n#> # ... with 39 more rows\n\ndiamonds %>% \n   select_if(is.numeric) %>%  # you can calculate cor only for numerical variables\n  cor() %>%  # correlation matrix\n  data.frame() %>% \n  rownames_to_column(var = \"X\") %>% \n  pivot_longer(-X, names_to = \"Y\") %>% \n  ggplot(aes(X, Y, fill = value)) + \n  geom_tile(color = \"black\") +\n  scale_fill_gradient2(midpoint = 0) # 0 should be white on the plot for correlations\neurostat::search_eurostat(\"employment\")\nunemployment_df <- eurostat::get_eurostat(\"enpe_lfsa_urgan\")\n\nunemployment_df\n#> # A tibble: 726 x 6\n#>    unit  sex   age    geo   time       values\n#>    <chr> <chr> <chr>  <chr> <date>      <dbl>\n#>  1 RT    F     Y15-24 AM    2019-01-01   34.4\n#>  2 RT    F     Y15-24 AZ    2019-01-01   14.2\n#>  3 RT    F     Y15-24 BY    2019-01-01    9.6\n#>  4 RT    F     Y15-24 GE    2019-01-01   32.9\n#>  5 RT    F     Y15-24 MD    2019-01-01    9.4\n#>  6 RT    F     Y15-24 UA    2019-01-01   15.3\n#>  7 RT    F     Y15-74 AM    2019-01-01   19.3\n#>  8 RT    F     Y15-74 AZ    2019-01-01    5.7\n#>  9 RT    F     Y15-74 BY    2019-01-01    3.2\n#> 10 RT    F     Y15-74 GE    2019-01-01   10.1\n#> # ... with 716 more rows\nunemployment_df <- unemployment_df %>% \n  filter(sex == \"T\" & age == \"Y15-74\") %>% \n  mutate(time = lubridate::year(time)) %>% \n  select(geo, time, unemployment = values)\nemployment_df <- eurostat::get_eurostat(\"enpe_lfsa_ergan\")\n\nemployment_df\n#> # A tibble: 458 x 6\n#>    unit  sex   age    geo   time       values\n#>    <chr> <chr> <chr>  <chr> <date>      <dbl>\n#>  1 RT    F     Y20-64 AM    2019-01-01   44.8\n#>  2 RT    F     Y20-64 AZ    2019-01-01   70.9\n#>  3 RT    F     Y20-64 BY    2019-01-01   77.4\n#>  4 RT    F     Y20-64 GE    2019-01-01   58.3\n#>  5 RT    F     Y20-64 MD    2019-01-01   46.8\n#>  6 RT    F     Y20-64 UA    2019-01-01   61.6\n#>  7 RT    M     Y20-64 AM    2019-01-01   66.6\n#>  8 RT    M     Y20-64 AZ    2019-01-01   77.9\n#>  9 RT    M     Y20-64 BY    2019-01-01   83  \n#> 10 RT    M     Y20-64 GE    2019-01-01   72.3\n#> # ... with 448 more rows\nemployment_df <- employment_df %>% \n  filter(sex == \"T\" & age == \"Y20-64\" & unit == \"RT\") %>% \n  mutate(time = lubridate::year(time)) %>% \n  select(geo, time, employment = values)\ndf <- full_join(x = employment_df, y = unemployment_df)\ndf %>% \n  filter(geo == \"GE\") %>% # values of Germany\n  ggplot() + \n  aes(x = time, y = unemployment) +\n  geom_line()\ndf %>% \n  filter(geo == \"GE\") %>% \n  ggplot() + \n  geom_line(aes(time, unemployment)) + \n  geom_line(aes(time, employment))\ndf %>% \n  filter(geo == \"GE\") %>% \n  pivot_longer(employment:unemployment) # color based on the name\n#> # A tibble: 30 x 4\n#>    geo    time name         value\n#>    <chr> <dbl> <chr>        <dbl>\n#>  1 GE     2019 employment    65.1\n#>  2 GE     2019 unemployment  11.6\n#>  3 GE     2018 employment    64.9\n#>  4 GE     2018 unemployment  12.7\n#>  5 GE     2017 employment    65.3\n#>  6 GE     2017 unemployment  13.9\n#>  7 GE     2016 employment    65.5\n#>  8 GE     2016 unemployment  14  \n#>  9 GE     2015 employment    66.5\n#> 10 GE     2015 unemployment  14.1\n#> # ... with 20 more rows\ndf %>% \n  filter(geo == \"GE\") %>% \n  pivot_longer(employment:unemployment) %>%\n  ggplot() +\n  aes(x = time, y = value, color = name) + \n  geom_line()\ndf %>% \n  filter(geo == \"GE\") %>% \n  ggplot() + \n  aes(x = unemployment, y = employment, label = time)  +\n  geom_path() + # observation are connected in prevalence\n  geom_text()"},{"path":"seminar5.html","id":"seminar5","chapter":"4 Webscraping with R","heading":"4 Webscraping with R","text":"Nowadays, manage huge part life online. important side-effect: can collect enormous data web researches. can access data shops, blogs, social media etc. target chapter give brief introduction can collect data effectively. need new package purpose: rvestWe scrape data hasznaltauto, online second hand car market Hungary. Lets navigate page browser lets click search.\nFigure 4.1: www.hasznaltauto.hu/\nNow copy paste new url browser Rstudio. first link want visit scraping. Lets assign url url R.\nFigure 4.2: Click search button.\nnext step load website R session. can done read_html function rvest package.Now can see webpage html codes RStudio. get open developer view browser.developer view, can find information relevant select using html_nodes function. Alternatively, however, simpler method. Add Selector Gadget browser. add-helps find ID item clicking . way, can navigate without web development skills. can easily install add-chrome edge, just search name first hit .\nFigure 4.3: Add Selector Gadget browser.\ncan activate add-menu browser.First, find IDs car ads. , first select name specific car mark everything want include. target make every car ads title yellow green, nothing else green.\nFigure 4.4: Using Selector Gadget find IDs car ads.\nID looking , put html_nodes function. code selects ad titles page.still html_code.want keep text element, use html_text function, interested url points , use thehtml_attr function. latter case, always necessary specify href element, ie web page referring .’ve now collected names ads url leading first page. next step collect data pages. However, downloading info sites lengthy process. Always try first pages first download sure program running without error.download data multiple pages ? Let’s see url changes go next page.look second page results list browser, can see link expanded “/page2” member compared previous url address. Continue “/ page3” page 3, etc.way can easily generate vector contains links first 1, 10, 100, 1000 even pages. Lets put data.frame.Taking advantage {purr} package, can load manipulate entire pages data frames transparent human-readable (tidy) way.require map function, haven’t talked using far.Map similar functions apply family. performs specific function element list / vector, result always comes form list.second example shows specify one function second input, without “~” “.”, first input map automatically first possible input specified function, elements added function follow order. present case, prepared random samples 1, 2, 3 elements, expected value samples 10, first input function rnorm number elements (n) second expected value (mean).now use map function inside themutate function, list actually column original table. elements list web pages loaded read_html function.Now let’s insert nodes column contains required points page, aurl_to_cars column, links extracted . Since already computationally intensive step, worth saving result. Save name environment won’t full unnecessary variables.now , need column links addresses, nested. first cell url_to_cars column contains hundred links. nesting option opens lot new doors process data manipulation. Use unnest function extract columns.can see nodes selection entirely perfect (usually ), matching elements duplications left.now can still remove items don’t fit . Fortunately, link behind , columns , unique[^can also use lists vectors.] service.now ready-made list available cars links. Let’s visit one browser see ’s next.","code":"\nlibrary(rvest)\nurl <- \"https://www.hasznaltauto.hu/talalatilista/PCOG2VGRR3RDAD [...]\" # long url\npage <- read_html(url)\n\npage\n#> {html_document}\n#> <html lang=\"hu-HU\">\n#> [1] <head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n#> [2] <body>\\n    <script type=\"text/javascript\">var utag_data = {\"website\":\"ha ...#> Error in knitr::include_graphics(\"images/dev_mode.png\"): Cannot find the file(s): \"images/dev_mode.png\"\nmy_node <- page %>% \n  html_nodes(\".cim-kontener a\")\n#> Error in xml_ns.xml_document(x): external pointer is not valid\n\nmy_node\n#> Error in eval(expr, envir, enclos): object 'my_node' not found\nname_of_the_car <- my_node %>% \n  html_text()\n#> Error in xml_text(x, trim = trim): object 'my_node' not found\n\nname_of_the_car\n#> Error in eval(expr, envir, enclos): object 'name_of_the_car' not found\nurl_to_car <- my_node %>% \n  html_attr(\"href\")\n#> Error in xml_attr(x, name, default = default): object 'my_node' not found\n\nurl_to_car\n#> Error in eval(expr, envir, enclos): object 'url_to_car' not found\nurl_ending <- str_c(\"/page\", 2:10)\n\nurl_ending\n#> [1] \"/page2\"  \"/page3\"  \"/page4\"  \"/page5\"  \"/page6\"  \"/page7\"  \"/page8\" \n#> [8] \"/page9\"  \"/page10\"\n\nurl_ending <- c(\"\", url_ending) # nothing to add at the first page\n\nurl_ending\n#>  [1] \"\"        \"/page2\"  \"/page3\"  \"/page4\"  \"/page5\"  \"/page6\"  \"/page7\" \n#>  [8] \"/page8\"  \"/page9\"  \"/page10\"\n\ncars_add_df <- tibble(url = str_c(url, url_ending))\n\ncars_add_df\n#> # A tibble: 10 x 1\n#>    url                                                                          \n#>    <chr>                                                                        \n#>  1 https://www.hasznaltauto.hu/talalatilista/PCOG2VGRR3RDADH4S56ACFGY3UFY652CQ5~\n#>  2 https://www.hasznaltauto.hu/talalatilista/PCOG2VGRR3RDADH4S56ACFGY3UFY652CQ5~\n#>  3 https://www.hasznaltauto.hu/talalatilista/PCOG2VGRR3RDADH4S56ACFGY3UFY652CQ5~\n#>  4 https://www.hasznaltauto.hu/talalatilista/PCOG2VGRR3RDADH4S56ACFGY3UFY652CQ5~\n#>  5 https://www.hasznaltauto.hu/talalatilista/PCOG2VGRR3RDADH4S56ACFGY3UFY652CQ5~\n#>  6 https://www.hasznaltauto.hu/talalatilista/PCOG2VGRR3RDADH4S56ACFGY3UFY652CQ5~\n#>  7 https://www.hasznaltauto.hu/talalatilista/PCOG2VGRR3RDADH4S56ACFGY3UFY652CQ5~\n#>  8 https://www.hasznaltauto.hu/talalatilista/PCOG2VGRR3RDADH4S56ACFGY3UFY652CQ5~\n#>  9 https://www.hasznaltauto.hu/talalatilista/PCOG2VGRR3RDADH4S56ACFGY3UFY652CQ5~\n#> 10 https://www.hasznaltauto.hu/talalatilista/PCOG2VGRR3RDADH4S56ACFGY3UFY652CQ5~\nmap(1:5, ~ .^2) # calculate the square of each element (lambda type function)\n#> [[1]]\n#> [1] 1\n#> \n#> [[2]]\n#> [1] 4\n#> \n#> [[3]]\n#> [1] 9\n#> \n#> [[4]]\n#> [1] 16\n#> \n#> [[5]]\n#> [1] 25\n\nmap(1:3, rnorm, 10) # generate rnrom distribution with 1,2,3 element \n#> [[1]]\n#> [1] 10.12159\n#> \n#> [[2]]\n#> [1] 8.041066 9.598428\n#> \n#> [[3]]\n#> [1]  9.182985  9.076562 10.020299\ncars_add_df %>% \n  mutate(\n    page = map(url, read_html)\n  )\n#> # A tibble: 10 x 2\n#>    url                                                                 page     \n#>    <chr>                                                               <list>   \n#>  1 https://www.hasznaltauto.hu/talalatilista/PCOG2VGRR3RDADH4S56ACFGY~ <xml_dcm~\n#>  2 https://www.hasznaltauto.hu/talalatilista/PCOG2VGRR3RDADH4S56ACFGY~ <xml_dcm~\n#>  3 https://www.hasznaltauto.hu/talalatilista/PCOG2VGRR3RDADH4S56ACFGY~ <xml_dcm~\n#>  4 https://www.hasznaltauto.hu/talalatilista/PCOG2VGRR3RDADH4S56ACFGY~ <xml_dcm~\n#>  5 https://www.hasznaltauto.hu/talalatilista/PCOG2VGRR3RDADH4S56ACFGY~ <xml_dcm~\n#>  6 https://www.hasznaltauto.hu/talalatilista/PCOG2VGRR3RDADH4S56ACFGY~ <xml_dcm~\n#>  7 https://www.hasznaltauto.hu/talalatilista/PCOG2VGRR3RDADH4S56ACFGY~ <xml_dcm~\n#>  8 https://www.hasznaltauto.hu/talalatilista/PCOG2VGRR3RDADH4S56ACFGY~ <xml_dcm~\n#>  9 https://www.hasznaltauto.hu/talalatilista/PCOG2VGRR3RDADH4S56ACFGY~ <xml_dcm~\n#> 10 https://www.hasznaltauto.hu/talalatilista/PCOG2VGRR3RDADH4S56ACFGY~ <xml_dcm~\ncars_add_df <- cars_add_df %>% \n  mutate(\n    page = map(url, read_html),\n    nodes = map(page, ~ html_nodes(., \".cim-kontener a\")),\n    ad_title = map(nodes, html_text),\n    url_to_cars = map(nodes, html_attr, \"href\")\n  )\ncars_add_df\n#> # A tibble: 10 x 5\n#>    url                                     page    nodes   ad_title  url_to_cars\n#>    <chr>                                   <list>  <list>  <list>    <list>     \n#>  1 https://www.hasznaltauto.hu/talalatili~ <xml_d~ <xml_n~ <chr [13~ <chr [136]>\n#>  2 https://www.hasznaltauto.hu/talalatili~ <xml_d~ <xml_n~ <chr [40~ <chr [40]> \n#>  3 https://www.hasznaltauto.hu/talalatili~ <xml_d~ <xml_n~ <chr [40~ <chr [40]> \n#>  4 https://www.hasznaltauto.hu/talalatili~ <xml_d~ <xml_n~ <chr [40~ <chr [40]> \n#>  5 https://www.hasznaltauto.hu/talalatili~ <xml_d~ <xml_n~ <chr [40~ <chr [40]> \n#>  6 https://www.hasznaltauto.hu/talalatili~ <xml_d~ <xml_n~ <chr [40~ <chr [40]> \n#>  7 https://www.hasznaltauto.hu/talalatili~ <xml_d~ <xml_n~ <chr [40~ <chr [40]> \n#>  8 https://www.hasznaltauto.hu/talalatili~ <xml_d~ <xml_n~ <chr [40~ <chr [40]> \n#>  9 https://www.hasznaltauto.hu/talalatili~ <xml_d~ <xml_n~ <chr [40~ <chr [40]> \n#> 10 https://www.hasznaltauto.hu/talalatili~ <xml_d~ <xml_n~ <chr [40~ <chr [40]>\ncars_add_df %>% \n  select(url_to_cars, ad_title) %>% \n  unnest()\n#> # A tibble: 496 x 2\n#>    url_to_cars                               ad_title                           \n#>    <chr>                                     <chr>                              \n#>  1 <NA>                                      P                                  \n#>  2 https://www.hasznaltauto.hu/szemelyauto/~ SSANGYONG KORANDO 1.5 Turbo e-XGI ~\n#>  3 https://www.hasznaltauto.hu/szemelyauto/~ SSANGYONG KORANDO 1.5 Turbo e-XGI ~\n#>  4 <NA>                                      P                                  \n#>  5 https://www.hasznaltauto.hu/szemelyauto/~ CITROEN GRAND C4 SPACETOURER C4Spa~\n#>  6 https://www.hasznaltauto.hu/szemelyauto/~ CITROEN GRAND C4 SPACETOURER C4Spa~\n#>  7 <NA>                                      P                                  \n#>  8 https://www.hasznaltauto.hu/szemelyauto/~ SUZUKI SWIFT 1.2 Dualjet Hybrid GL+\n#>  9 https://www.hasznaltauto.hu/szemelyauto/~ SUZUKI SWIFT 1.2 Dualjet Hybrid GL+\n#> 10 <NA>                                      P                                  \n#> # ... with 486 more rows\ncars_add_df <- cars_add_df %>% \n  select(url_to_cars, ad_title) %>% \n  unnest() %>% \n  na.omit() %>% # remove rows where url_to_cars is missing (NA)\n  unique() # delete duplications\n\ncars_add_df\n#> # A tibble: 232 x 2\n#>    url_to_cars                             ad_title                             \n#>    <chr>                                   <chr>                                \n#>  1 https://www.hasznaltauto.hu/szemelyaut~ SSANGYONG KORANDO 1.5 Turbo e-XGI St~\n#>  2 https://www.hasznaltauto.hu/szemelyaut~ CITROEN GRAND C4 SPACETOURER C4Space~\n#>  3 https://www.hasznaltauto.hu/szemelyaut~ SUZUKI SWIFT 1.2 Dualjet Hybrid GL+  \n#>  4 https://www.hasznaltauto.hu/szemelyaut~ PEUGEOT 208 1.2 PureTech Active Acti~\n#>  5 https://www.hasznaltauto.hu/szemelyaut~ OPEL COMBO Life 1.2 T Enjoy 2.0t XL ~\n#>  6 https://www.hasznaltauto.hu/szemelyaut~ OPEL INSIGNIA Grand Sport 1.4 T Busi~\n#>  7 https://www.hasznaltauto.hu/szemelyaut~ OPEL ZAFIRA LIFE 1.5 D Business Edit~\n#>  8 https://www.hasznaltauto.hu/szemelyaut~ SUZUKI VITARA 1.4 Hybrid GL+         \n#>  9 https://www.hasznaltauto.hu/szemelyaut~ SUZUKI IGNIS 1.2 Hybrid GL+          \n#> 10 https://www.hasznaltauto.hu/szemelyaut~ CITROEN C5 AIRCROSS 1.2 PureTech Feel\n#> # ... with 222 more rows\ntables_form_page <- url_to_car %>% \n  na.omit() %>% \n  first() %>% \n  read_html() %>% \n  html_table(fill = TRUE) %>% \n  keep(~ ncol(.) == 2)\n\n# apply\n\ncars\napply(cars, 2, mean)\nx <- 1:10\nx\nlapply(x, function(x) x^2)\nsapply(x, function(x) x^2)\nmap(x, ~ .^2) # same with tidy method\nmap_dbl(x, ~ .^2)\n\n# map\n\ntables_form_page %>% \n  map(~ set_names(., \"x\", \"y\"))\n\ntables_form_page %>% \n  map(~ set_names(., \"x\", \"y\")) %>% \n  bind_rows() # merge the tables\n\nget_data <- function(url_to_car) {\n  url_to_car %>% \n    read_html() %>% \n    html_table(fill = TRUE) %>% \n    keep(~ ncol(.) == 2) %>% \n    map(~ set_names(., \"x\", \"y\")) %>% \n    bind_rows()\n}\n\nget_data(\"https://www.hasznaltauto.hu/szemelyauto/suzuki/swift/suzuki_swift_1.2_dualjet_hybrid_gl_plusz-16320785\")\n\nurl_to_car %>% \n  na.omit() %>% \n  head() %>% \n  map(get_data)\n\n\"https://www.hasznaltauto.hu/talalatilista/PCOG2VG3R3RDADH5S56ACFHGCYPHPBIGNGCUMWTJLYVUGTIJJVRJJJGVADRN7V3JJNUVRHTKDXN7DSPRJFA44PXEYXFWSJSFAUAUW4QK23MIQBLDKMU7YGIN5IJ5JAK2NAXAL2FUODG7ROYUDNVFJQAQHIQPMNQYKCB4XDNSJ5APR2OBC4U3A5XZ77KY7CNBQNE6ZQM7FXUJAH6ATG5KKJWFWT634SKRQIB3WVNASV7VFEGFNOASN6ZEY4ZTP2CQ54Y5BE3UTSWFZQMMPQBQK4YQROGZYJAZLLBCDQABPKXBGKLWJSPWWVYF3VS6RMKUTMA3ZXMUV7RNBVZ27A4J26LHSOLMN6ZDRVP553POVKYTRH3E6AX3URTN2ET2U7PNJ6HOZNZKWBTZH4PANXWQHGJ7ZKDS6R4GQIRLWKV26RV5X5N5LL3TU5AEH2SFA7XJXIPGLS5F2IA53YAFAOXIEXHVI5YLDIICWUPBALQJ5JMPWA7KPAOGW5HTDM3CYOUEKSLQCHHJKKUWQN65C6YTIO5WNAEJKGNVE3UK3F6Z2RWGVMBHFCD5GQDLHAJHWF7ERO6KQ3VF5XJJLHDWOELOHLELM4YZ45PRHTDPGLT6CGFSWBZT2YGG3CNOO3RZXJHQ4BTO4Y6HKCK3GKIN3SU5OGR5EYUFGZ6FGSNDGVMRFJLV2WRR4PZTIEDAXQRS4JXPZ4K3XOI24OXXC5NUKM74SQQZIWGVLCHL644WYNBEJVYYNLWZT5LD3QABZUY44TSONNPVQ5G7XERHW2WGHELAD7PRQFUEHFXW4SUBZY3P3XHYEX7SDBSXWV22THSKV4OJ6M2LIJ7U7GHFYCO2RR4F4O4R3HDL62K3DO2CHMWXP5T7RFKA/page2\"  \n\nurl\n\nmany_urls <- c(\"\", str_c(\"/page\", 2:10))\nmany_urls\n\ntibble(url = str_c(url, many_urls)) %>%\n  sample_n(2) %>% \n  mutate(\n    page = map(url, read_html),\n    url_to_car = map(page, html_nodes, \".cim-kontener a\"),\n    car = map(url_to_car, html_text),\n    url_to_car = map(url_to_car, html_attr, \"href\")\n  ) %>% \n  select(car, url_to_car) %>% \n  unnest(cols = c(car, url_to_car)) %>% \n  filter(!is.na(url_to_car))\n\ncars_df <- tibble(url = str_c(url, many_urls)) %>%\n  mutate(\n    page = map(url, read_html),\n    url_to_car = map(page, html_nodes, \".cim-kontener a\"),\n    car = map(url_to_car, html_text),\n    url_to_car = map(url_to_car, html_attr, \"href\")\n  ) %>% \n  select(car, url_to_car) %>% \n  unnest(cols = c(car, url_to_car)) %>% \n  filter(!is.na(url_to_car))\n\ncars_df %>% \n  sample_n(2) %>% \n  mutate(\n    data = map(url_to_car, get_data)\n  ) %>% \n  unnest(data) %>% \n  select(-url_to_car)\n\ncars_data_df <- cars_df %>% \n  mutate(\n    data = map(url_to_car, get_data)\n  ) %>% \n  unnest(data) %>% \n  pivot_wider(names_from = x, values_from = y) %>% \n  janitor::clean_names()\n\n\nsafely_read_html <- possibly(read_html, NA, quiet = FALSE)\n\nsleepy_read_html <- function(url) {\n  page <- safely_read_html(url)\n  \n  for (i in 1:3) {\n    if (is.na(page)) {\n      Sys.sleep(2)\n      message(\"I have to be patient! :)\")\n      page <- safely_read_html(url)\n    }\n  }\n  \n  page\n}\n\nget_data <- function(url_to_car) {\n  page <- url_to_car %>% \n    sleepy_read_html()\n  \n  if (!is.na(page)) {\n    \n  page %>% \n    html_table(fill = TRUE) %>% \n    keep(~ ncol(.) == 2) %>% \n    map(~ set_names(., \"x\", \"y\")) %>% \n    bind_rows()\n  } else {\n    tibble(x = as.character(NA), y = as.character(NA))\n  }\n}\n\ncars_data_df <- cars_df %>% \n  unique() %>% \n  mutate(\n    data = map(url_to_car, get_data)\n  ) %>% \n  unnest(data) %>% \n  pivot_wider(names_from = x, values_from = y) %>% \n  janitor::clean_names()"}]
